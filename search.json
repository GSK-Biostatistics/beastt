[{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://gsk-biostatistics.github.io/beastt/articles/binary.html","id":"introduction-and-data-description","dir":"Articles","previous_headings":"","what":"Introduction and Data Description","title":"Binary Outcome","text":"example, illustrate use Bayesian dynamic borrowing (BDB) inclusion inverse probability weighting balance baseline covariate distributions external internal datasets. particular example considers hypothetical trial binary outcome, objective use BDB IPWs construct posterior distribution control response rate θC\\theta_C. use simulated internal external datasets package dataset binary response variable (1: positive response; 0: otherwise) four baseline covariates balance. external control dataset sample size 150 participants, distributions four covariates follows: - Covariate 1: normal mean standard deviation approximately 65 10, respectively - Covariate 2: binary (0 vs. 1) approximately 30% participants level 1 - Covariate 3: binary (0 vs. 1) approximately 40% participants level 1 - Covariate 4: binary (0 vs. 1) approximately 50% participants level 1 internal dataset 160 participants 80 participants control arm active treatment arms. covariate distributions arm follows: - Covariate 1: normal mean standard deviation approximately 62 8, respectively - Covariate 2: binary (0 vs. 1) approximately 40% participants level 1 - Covariate 3: binary (0 vs. 1) approximately 40% participants level 1 - Covariate 4: binary (0 vs. 1) approximately 60% participants level 1","code":"library(beastt) library(distributional) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) set.seed(1234)  summary(int_binary_df) #>      subjid            cov1            cov2             cov3        #>  Min.   :  1.00   Min.   :46.00   Min.   :0.0000   Min.   :0.0000   #>  1st Qu.: 40.75   1st Qu.:57.00   1st Qu.:0.0000   1st Qu.:0.0000   #>  Median : 80.50   Median :62.00   Median :0.0000   Median :0.0000   #>  Mean   : 80.50   Mean   :61.83   Mean   :0.3688   Mean   :0.3625   #>  3rd Qu.:120.25   3rd Qu.:67.00   3rd Qu.:1.0000   3rd Qu.:1.0000   #>  Max.   :160.00   Max.   :85.00   Max.   :1.0000   Max.   :1.0000   #>       cov4             trt            y        #>  Min.   :0.0000   Min.   :0.0   Min.   :0.00   #>  1st Qu.:0.0000   1st Qu.:0.0   1st Qu.:0.00   #>  Median :1.0000   Median :0.5   Median :1.00   #>  Mean   :0.5563   Mean   :0.5   Mean   :0.65   #>  3rd Qu.:1.0000   3rd Qu.:1.0   3rd Qu.:1.00   #>  Max.   :1.0000   Max.   :1.0   Max.   :1.00 summary(ex_binary_df) #>      subjid            cov1            cov2             cov3        #>  Min.   :  1.00   Min.   :37.00   Min.   :0.0000   Min.   :0.0000   #>  1st Qu.: 38.25   1st Qu.:58.00   1st Qu.:0.0000   1st Qu.:0.0000   #>  Median : 75.50   Median :64.00   Median :0.0000   Median :0.0000   #>  Mean   : 75.50   Mean   :64.28   Mean   :0.3533   Mean   :0.4533   #>  3rd Qu.:112.75   3rd Qu.:70.00   3rd Qu.:1.0000   3rd Qu.:1.0000   #>  Max.   :150.00   Max.   :90.00   Max.   :1.0000   Max.   :1.0000   #>       cov4              y          #>  Min.   :0.0000   Min.   :0.0000   #>  1st Qu.:0.0000   1st Qu.:0.0000   #>  Median :0.0000   Median :1.0000   #>  Mean   :0.4733   Mean   :0.5133   #>  3rd Qu.:1.0000   3rd Qu.:1.0000   #>  Max.   :1.0000   Max.   :1.0000"},{"path":"https://gsk-biostatistics.github.io/beastt/articles/binary.html","id":"propensity-scores-and-inverse-probability-weights","dir":"Articles","previous_headings":"","what":"Propensity Scores and Inverse Probability Weights","title":"Binary Outcome","text":"covariate data external internal datasets, can calculate propensity scores ATT inverse probability weights (IPWs) internal external control participants using calc_prop_scr function. creates propensity score object can use calculating inverse probability weighted power prior next step. Note: reading external internal datasets calc_prop_scr, sure include arms want balance covariate distributions (typically internal external control arms). example, want balance covariate distributions external control arm similar internal control arm, exclude internal active treatment arm data function. order check suitability external data, can create variety diagnostic plots. first plot might want histogram overlapping propensity score distributions datasets. get , use prop_scr_hist function. function takes propensity score object made previous step, can optionally supply variable want look (either propensity score IPW). default, plot propensity scores. Additionally, can look densities rather histograms using prop_scr_dens function. looking IPWs either histogram density functions, important note IPWs external control participants shown ATT IPWs internal control participants equal 1.   final plot might want look love plot visualize absolute standardized mean differences (unadjusted adjusted IPWs) covariates internal external data. , use prop_scr_love function. Like previous function, required parameter function propensity score object, can also provide location along x-axis vertical reference line.","code":"ps_obj <- calc_prop_scr(internal_df = filter(int_binary_df, trt == 0),                         external_df = ex_binary_df,                         id_col = subjid,                         model = ~ cov1 + cov2 + cov3 + cov4) ps_obj #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> • cov1 + cov2 + cov3 + cov4 #>  #> ── Propensity Scores and Weights ─────────────────────────────────────────────── #> • Effective sample size of the external arm: 81 #> # A tibble: 150 × 4 #>    subjid Internal `Propensity Score` `Inverse Probability Weight` #>     <int> <lgl>                 <dbl>                        <dbl> #>  1      1 FALSE                 0.333                        0.500 #>  2      2 FALSE                 0.288                        0.405 #>  3      3 FALSE                 0.539                        1.17  #>  4      4 FALSE                 0.546                        1.20  #>  5      5 FALSE                 0.344                        0.524 #>  6      6 FALSE                 0.393                        0.646 #>  7      7 FALSE                 0.390                        0.639 #>  8      8 FALSE                 0.340                        0.515 #>  9      9 FALSE                 0.227                        0.294 #> 10     10 FALSE                 0.280                        0.389 #> # ℹ 140 more rows #>  #> ── Absolute Standardized Mean Difference ─────────────────────────────────────── #> # A tibble: 4 × 3 #>   covariate diff_unadj diff_adj #>   <chr>          <dbl>    <dbl> #> 1 cov1          0.339  0.0461   #> 2 cov2          0.0450 0.0204   #> 3 cov3          0.160  0.000791 #> 4 cov4          0.308  0.00857 prop_scr_hist(ps_obj) prop_scr_dens(ps_obj, variable = \"ipw\") prop_scr_love(ps_obj, reference_line = 0.1)"},{"path":"https://gsk-biostatistics.github.io/beastt/articles/binary.html","id":"inverse-probability-weighted-power-prior","dir":"Articles","previous_headings":"","what":"Inverse Probability Weighted Power Prior","title":"Binary Outcome","text":"Now created assessed propensity score object, can read calc_power_prior_beta function calculate beta inverse probability weighted power prior θC\\theta_C. calculate power prior, need supply following information: weighted object (propensity score object created ) response variable name (case yy) initial prior, form beta distributional object (e.g., Beta(0.5,0.5)\\mbox{Beta}(0.5, 0.5)) power prior, might want plot . , use plot_dist function.","code":"pwr_prior <- calc_power_prior_beta(ps_obj,                                    response = y,                                    prior = dist_beta(0.5, 0.5)) plot_dist(pwr_prior)"},{"path":"https://gsk-biostatistics.github.io/beastt/articles/binary.html","id":"inverse-probability-weighted-robust-mixture-prior","dir":"Articles","previous_headings":"","what":"Inverse Probability Weighted Robust Mixture Prior","title":"Binary Outcome","text":"can robustify beta power prior θC\\theta_C adding vague component create robust mixture prior (RMP). define vague component Beta(0.5,0.5)\\mbox{Beta}(0.5, 0.5) prior, use dist_mixture function distributional package construct RMP 0.5 weight component. function, can name different components RMP (e.g., “informative” “vague”). general, can define prior mixture distribution arbitrary number beta components.","code":"vague_prior <- dist_beta(0.5, 0.5) mix_prior <- dist_mixture(informative = pwr_prior,                           vague = vague_prior,                           weights = c(0.5, 0.5)) plot_dist(\"Power Prior\" = pwr_prior,           \"Vague Prior\" = vague_prior,           \"Robust Mixture Prior\" = mix_prior)"},{"path":"https://gsk-biostatistics.github.io/beastt/articles/binary.html","id":"posterior-distributions","dir":"Articles","previous_headings":"","what":"Posterior Distributions","title":"Binary Outcome","text":"create posterior distribution θC\\theta_C, can pass resulting RMP calc_post_beta function. see resulting posterior distribution also mixture beta components. Note: reading internal data directly calc_post_beta, sure include arm interest (e.g., internal control arm creating posterior distribution θC\\theta_C).  Next, create posterior distribution response rate active treatment arm θT\\theta_T reading internal data corresponding arm calc_post_beta function. case, assume vague beta prior. noted earlier, sure read data internal active treatment arm excluding internal control data.","code":"post_control <- calc_post_beta(filter(int_binary_df, trt == 0),                                response = y,                                prior = mix_prior) plot_dist(post_control) post_treated <- calc_post_beta(internal_data = filter(int_binary_df, trt == 1),                                response = y,                                prior = vague_prior) plot_dist(\"Control Posterior\" = post_control,           \"Treatment Posterior\" = post_treated)"},{"path":"https://gsk-biostatistics.github.io/beastt/articles/binary.html","id":"posterior-summary-statistics-and-samples","dir":"Articles","previous_headings":"","what":"Posterior Summary Statistics and Samples","title":"Binary Outcome","text":"posterior distributions θC\\theta_C θT\\theta_T saved distributional objects, can use several functions distributional package calculate posterior summary statistics sample distributions. Using posterior distribution θC\\theta_C example, illustrate several functions . Posterior summary statistics: Highest density regions using hdr function: Credible intervals using either hilo function quantile function: Posterior probabilities (e.g., Pr(θC<0.5|D)Pr(\\theta_C < 0.5 | D)) using cdf function: Posterior (log) densities given value: addition calculating posterior summary statistics, can sample posterior distributions using generate function. , randomly sample 100,000 draws posterior distribution θC\\theta_C plot histogram sample.  Similarly, sample posterior distribution θT\\theta_T.  define marginal treatment effect difference active treatment response rate control response rate (.e., θT−θC\\theta_T - \\theta_C). can obtain sample posterior distribution θT−θC\\theta_T - \\theta_C subtracting posterior sample θC\\theta_C posterior sample θT\\theta_T.  Suppose want test hypotheses H0:θT−θC≤0H_0: \\theta_T - \\theta_C \\le 0 versus H1:θT−θC>0H_1: \\theta_T - \\theta_C > 0. can use posterior sample θT−θC\\theta_T - \\theta_C calculate posterior probability Pr(θT−θC>0∣D)Pr(\\theta_T - \\theta_C > 0 \\mid D) (.e., probability favor H1H_1), conclude sufficient evidence favor alternative hypothesis Pr(θT−θC>0∣D)>0.975Pr(\\theta_T - \\theta_C > 0 \\mid D) > 0.975. see posterior probability greater 0.975, hence sufficient evidence support alternative hypothesis. Using parameters function distributional package, can extract parameters posterior distribution consists single component (.e., single beta distribution). example, can extract shape 1 shape 2 parameters beta posterior distribution θT\\theta_T. can also use parameters function extract mixture weights associated two beta components posterior distribution θC\\theta_C. Lastly, calculate effective sample size posterior distribution θC\\theta_C using method Pennello Thompson (2008). , first must construct posterior distribution θC\\theta_Cwithout borrowing external control data (e.g., using vague prior).","code":"c(mean = mean(post_control),   median = median(post_control),   variance = variance(post_control)) #>        mean      median    variance  #> 0.541262322 0.541589059 0.001697325 hdr(post_control)        # 95% HDR #> <hdr[1]> #> [1] [0.4605526, 0.621634]95 hdr(post_control, 90)    # 90% HDR #> <hdr[1]> #> [1] [0.4740822, 0.6087946]90 hilo(post_control)       # 95% credible interval #> <hilo[1]> #> [1] [0.4594412, 0.6211411]95 hilo(post_control, 90)   # 90% credible interval #> <hilo[1]> #> [1] [0.4732915, 0.6081643]90 quantile(post_control, c(.025, .975))[[1]]    # 95% CrI via quantile function #> [1] 0.4594412 0.6211411 cdf(post_control, q = .5)   # Pr(theta_C < 0.5 | D) #> [1] 0.1552946 density(post_control, at = .5)                # density at 0.5 #> [1] 5.732071 density(post_control, at = .5, log = TRUE)    # log density at 0.5 #> [1] 1.746077 samp_control <- generate(x = post_control, times = 100000)[[1]] ggplot(data.frame(samp = samp_control), aes(x = samp)) +   labs(y = \"Density\", x = expression(theta[C])) +   ggtitle(expression(paste(\"Posterior Samples of \", theta[C]))) +   geom_histogram(aes(y = after_stat(density)), color = \"#5398BE\", fill = \"#5398BE\",                  position = \"identity\", binwidth = .01, alpha = 0.5) +   geom_density(color = \"black\") +   coord_cartesian(xlim = c(-0.1, 1.1)) +   theme_bw() samp_treated <- generate(x = post_treated, times = 100000)[[1]] ggplot(data.frame(samp = samp_treated), aes(x = samp)) +   labs(y = \"Density\", x = expression(theta[T])) +   ggtitle(expression(paste(\"Posterior Samples of \", theta[T]))) +   geom_histogram(aes(y = after_stat(density)), color = \"#FFA21F\", fill = \"#FFA21F\",                  position = \"identity\", binwidth = .01, alpha = 0.5) +   geom_density(color = \"black\") +   coord_cartesian(xlim = c(-0.1, 1.1)) +   theme_bw() samp_trt_diff <- samp_treated - samp_control ggplot(data.frame(samp = samp_trt_diff), aes(x = samp)) +   labs(y = \"Density\", x = expression(paste(theta[T], \" - \", theta[C]))) +   ggtitle(expression(paste(\"Posterior Samples of \", theta[T], \" - \", theta[C]))) +   geom_histogram(aes(y = after_stat(density)), color = \"#FF0000\", fill = \"#FF0000\",                  position = \"identity\", binwidth = .01, alpha = 0.5) +   geom_density(color = \"black\") +   coord_cartesian(xlim = c(-0.1, 1.1)) +   theme_bw() mean(samp_trt_diff > 0) #> [1] 0.99947 parameters(post_treated) #>   shape1 shape2 #> 1   61.5   19.5 parameters(post_control)$w[[1]] #> informative       vague  #>   0.8879774   0.1120226 post_control_no_brrw <- calc_post_beta(filter(int_binary_df, trt == 0),                                        response = y,                                        prior = vague_prior) n_int_ctrl <- nrow(filter(int_binary_df, trt == 0))   # sample size of internal control arm var_no_brrw <- variance(post_control_no_brrw)    # post variance of theta_C without borrowing var_brrw <- variance(post_control)               # post variance of theta_C with borrowing ess <- n_int_ctrl * var_no_brrw / var_brrw       # effective sample size ess #> [1] 142.9097"},{"path":"https://gsk-biostatistics.github.io/beastt/articles/continuous.html","id":"introduction-and-data-description","dir":"Articles","previous_headings":"","what":"Introduction and Data Description","title":"Normal Outcome (Known SD)","text":"example, illustrate use Bayesian dynamic borrowing (BDB) inclusion inverse probability weighting balance baseline covariate distributions external internal datasets. particular example considers hypothetical trial cross sectional normal outcome known standard deviation (SD) treatment arm (external control arm internal arms), objective use BDB IPWs construct posterior distribution control mean θC\\theta_C. use simulated internal external datasets package dataset normally distributed response variable four baseline covariates balance. external control dataset sample size 150 participants, distributions four covariates follows: - Covariate 1: normal mean standard deviation approximately 50 10, respectively - Covariate 2: binary (0 vs. 1) approximately 20% participants level 1 - Covariate 3: binary (0 vs. 1) approximately 60% participants level 1 - Covariate 4: binary (0 vs. 1) approximately 30% participants level 1 internal dataset 120 participants 60 participants control active treatment arms. covariate distributions arm follows: - Covariate 1: normal mean standard deviation approximately 55 8, respectively - Covariate 2: binary (0 vs. 1) approximately 30% participants level 1 - Covariate 3: binary (0 vs. 1) approximately 50% participants level 1 - Covariate 4: binary (0 vs. 1) approximately 30% participants level 1 assume standard deviations external internal response data known equal 0.15.","code":"library(tibble) library(distributional) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) set.seed(1234)  summary(int_norm_df) #>      subjid            cov1            cov2             cov3        #>  Min.   :  1.00   Min.   :32.00   Min.   :0.0000   Min.   :0.0000   #>  1st Qu.: 30.75   1st Qu.:49.00   1st Qu.:0.0000   1st Qu.:0.0000   #>  Median : 60.50   Median :55.00   Median :0.0000   Median :1.0000   #>  Mean   : 60.50   Mean   :54.16   Mean   :0.2833   Mean   :0.5083   #>  3rd Qu.: 90.25   3rd Qu.:59.00   3rd Qu.:1.0000   3rd Qu.:1.0000   #>  Max.   :120.00   Max.   :69.00   Max.   :1.0000   Max.   :1.0000   #>       cov4           trt            y             #>  Min.   :0.00   Min.   :0.0   Min.   :-0.009368   #>  1st Qu.:0.00   1st Qu.:0.0   1st Qu.: 0.515350   #>  Median :0.00   Median :0.5   Median : 0.683271   #>  Mean   :0.25   Mean   :0.5   Mean   : 0.697265   #>  3rd Qu.:0.25   3rd Qu.:1.0   3rd Qu.: 0.869011   #>  Max.   :1.00   Max.   :1.0   Max.   : 1.399801 summary(ex_norm_df) #>      subjid            cov1            cov2             cov3          cov4     #>  Min.   :  1.00   Min.   :27.00   Min.   :0.0000   Min.   :0.0   Min.   :0.0   #>  1st Qu.: 38.25   1st Qu.:42.00   1st Qu.:0.0000   1st Qu.:0.0   1st Qu.:0.0   #>  Median : 75.50   Median :48.00   Median :0.0000   Median :0.5   Median :0.0   #>  Mean   : 75.50   Mean   :49.03   Mean   :0.2267   Mean   :0.5   Mean   :0.3   #>  3rd Qu.:112.75   3rd Qu.:55.00   3rd Qu.:0.0000   3rd Qu.:1.0   3rd Qu.:1.0   #>  Max.   :150.00   Max.   :75.00   Max.   :1.0000   Max.   :1.0   Max.   :1.0   #>        y           #>  Min.   :-0.2778   #>  1st Qu.: 0.3669   #>  Median : 0.5921   #>  Mean   : 0.5893   #>  3rd Qu.: 0.8277   #>  Max.   : 1.3438 sd_external_control <- 0.15 sd_internal_control <- 0.15 sd_internal_treated <- 0.15"},{"path":"https://gsk-biostatistics.github.io/beastt/articles/continuous.html","id":"propensity-scores-and-inverse-probability-weights","dir":"Articles","previous_headings":"","what":"Propensity Scores and Inverse Probability Weights","title":"Normal Outcome (Known SD)","text":"covariate data external internal datasets, can calculate propensity scores ATT inverse probability weights (IPWs) internal external control participants using calc_prop_scr function. creates propensity score object can use calculating inverse probability weighted power prior next step. Note: reading external internal datasets calc_prop_scr, sure include arms want balance covariate distributions (typically internal external control arms). example, want balance covariate distributions external control arm similar internal control arm, exclude internal active treatment arm data function. order check suitability external data, can create variety diagnostic plots. first plot might want histogram overlapping propensity score distributions datasets. get , use prop_scr_hist function. function takes propensity score object made previous step, can optionally supply variable want look (either propensity score IPW). default, plot propensity scores. Additionally, can look densities rather histograms using prop_scr_dens function. looking IPWs either histogram density functions, important note IPWs external control participants shown ATT IPWs internal control participants equal 1.   final plot might want look love plot visualize absolute standardized mean differences (unadjusted adjusted IPWs) covariates internal external data. , use prop_scr_love function. Like previous function, required parameter function propensity score object, can also provide location along x-axis vertical reference line.","code":"ps_model <- ~ cov1 + cov2 + cov3 + cov4 ps_obj <- calc_prop_scr(internal_df = filter(int_norm_df, trt == 0),                          external_df = ex_norm_df,                          id_col = subjid,                         model = ps_model)  ps_obj #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> • cov1 + cov2 + cov3 + cov4 #>  #> ── Propensity Scores and Weights ─────────────────────────────────────────────── #> • Effective sample size of the external arm: 61 #> # A tibble: 150 × 4 #>    subjid Internal `Propensity Score` `Inverse Probability Weight` #>     <int> <lgl>                 <dbl>                        <dbl> #>  1      1 FALSE                 0.181                        0.221 #>  2      2 FALSE                 0.351                        0.542 #>  3      3 FALSE                 0.456                        0.840 #>  4      4 FALSE                 0.115                        0.130 #>  5      5 FALSE                 0.364                        0.572 #>  6      6 FALSE                 0.377                        0.604 #>  7      7 FALSE                 0.131                        0.150 #>  8      8 FALSE                 0.259                        0.349 #>  9      9 FALSE                 0.235                        0.308 #> 10     10 FALSE                 0.207                        0.261 #> # ℹ 140 more rows #>  #> ── Absolute Standardized Mean Difference ─────────────────────────────────────── #> # A tibble: 4 × 3 #>   covariate diff_unadj diff_adj #>   <chr>          <dbl>    <dbl> #> 1 cov1          0.506   0.104   #> 2 cov2          0.0548  0.104   #> 3 cov3          0.0667  0.00115 #> 4 cov4          0.275   0.00266 prop_scr_hist(ps_obj) prop_scr_dens(ps_obj, variable = \"ipw\") prop_scr_love(ps_obj, reference_line = 0.1)"},{"path":"https://gsk-biostatistics.github.io/beastt/articles/continuous.html","id":"inverse-probability-weighted-power-prior","dir":"Articles","previous_headings":"","what":"Inverse Probability Weighted Power Prior","title":"Normal Outcome (Known SD)","text":"Now created assessed propensity score object, can read calc_power_prior_norm function calculate normal inverse probability weighted power prior θC\\theta_C. calculate power prior, need supply following information: weighted object (propensity score object created ) response variable name (case yy) initial prior, form normal distributional object (e.g., N(0.5,sd=10)\\mbox{N}(0.5, \\mbox{sd} = 10)) SD external control response data, assumed known prior external control SD optional. prior provided, improper uniform prior used initial prior; .e., π(θC)∝1\\pi(\\theta_C) \\propto 1. external control SD initial prior specified (.e., prior external_sd arguments set NULL), non-standardized tt power prior created (covered vignette). example, define initial prior vague normal distribution mean 0.5 SD 10. power prior, might want plot . , use plot_dist function.","code":"pwr_prior <- calc_power_prior_norm(ps_obj,                                    response = y,                                    prior = dist_normal(0.5, 10),                                     external_sd = sd_external_control) plot_dist(pwr_prior)"},{"path":"https://gsk-biostatistics.github.io/beastt/articles/continuous.html","id":"inverse-probability-weighted-robust-mixture-prior","dir":"Articles","previous_headings":"","what":"Inverse Probability Weighted Robust Mixture Prior","title":"Normal Outcome (Known SD)","text":"can robustify normal power prior θC\\theta_C adding vague component create robust mixture prior (RMP). define vague component normal distribution mean power prior variance nexn_{ex} times greater variance power prior, nexn_{ex} denotes sample size external control arm. construct RMP two components, use robustify_norm function place 0.5 weight component. two components resulting RMP labeled “informative” “vague”. alternative using robustify_norm, can instead use dist_mixture function create mixture prior arbitrary number normal /tt components. component prior tt distribution, component approximated mixture two normal distributions.","code":"n_external <- nrow(ex_norm_df) mix_prior <- robustify_norm(pwr_prior, n_external, weights = c(0.5, 0.5)) plot_dist(\"Power Prior\" = pwr_prior,           \"Vague Prior\" = dist_normal(mean = mix_means(mix_prior)[\"vague\"],                                       sd = mix_sigmas(mix_prior)[\"vague\"]),           \"Robust Mixture Prior\" = mix_prior)"},{"path":"https://gsk-biostatistics.github.io/beastt/articles/continuous.html","id":"posterior-distributions","dir":"Articles","previous_headings":"","what":"Posterior Distributions","title":"Normal Outcome (Known SD)","text":"create posterior distribution θC\\theta_C, can pass resulting RMP calc_post_norm function. assuming SD internal response data known, resulting posterior distribution also mixture normal components (case SD unknown covered vignette). Note: reading internal data directly calc_post_norm, sure include arm interest (e.g., internal control arm creating posterior distribution θC\\theta_C).  Next, create posterior distribution mean active treatment arm θT\\theta_T reading internal data corresponding arm calc_post_norm function assuming SD internal active treatment arm equal 0.15. case, use vague component RMP normal prior. noted earlier, sure read data internal active treatment arm excluding internal control data.","code":"post_control <- calc_post_norm(filter(int_norm_df, trt == 0),                                response = y,                                 prior = mix_prior,                                internal_sd = sd_internal_control) plot_dist(post_control) post_treated <- calc_post_norm(internal_data = filter(int_norm_df, trt == 1),                                response = y,                                prior = dist_normal(mean = mix_means(mix_prior)[\"vague\"],                                                    sd = mix_sigmas(mix_prior)[\"vague\"]),                                internal_sd = sd_internal_treated) plot_dist(\"Control Posterior\" = post_control,           \"Treatment Posterior\" = post_treated)"},{"path":"https://gsk-biostatistics.github.io/beastt/articles/continuous.html","id":"posterior-summary-statistics-and-samples","dir":"Articles","previous_headings":"","what":"Posterior Summary Statistics and Samples","title":"Normal Outcome (Known SD)","text":"posterior distributions θC\\theta_C θT\\theta_T saved distributional objects, can use several functions distributional package calculate posterior summary statistics sample distributions. Using posterior distribution θC\\theta_C example, illustrate several functions . Posterior summary statistics: Highest density regions using hdr function: Credible intervals using either hilo function quantile function: Posterior probabilities (e.g., Pr(θC<0.7|D)Pr(\\theta_C < 0.7 | D)) using cdf function: Posterior (log) densities given value: addition calculating posterior summary statistics, can sample posterior distributions using generate function. , randomly sample 100,000 draws posterior distribution θC\\theta_C plot histogram sample.  Similarly, sample posterior distribution θT\\theta_T.  define marginal treatment effect difference active treatment mean control mean (.e., θT−θC\\theta_T - \\theta_C). can obtain sample posterior distribution θT−θC\\theta_T - \\theta_C subtracting posterior sample θC\\theta_C posterior sample θT\\theta_T.  Suppose want test hypotheses H0:θT−θC≤0H_0: \\theta_T - \\theta_C \\le 0 versus H1:θT−θC>0H_1: \\theta_T - \\theta_C > 0. can use posterior sample θT−θC\\theta_T - \\theta_C calculate posterior probability Pr(θT−θC>0∣D)Pr(\\theta_T - \\theta_C > 0 \\mid D) (.e., probability favor H1H_1), conclude sufficient evidence favor alternative hypothesis Pr(θT−θC>0∣D)>0.975Pr(\\theta_T - \\theta_C > 0 \\mid D) > 0.975. see posterior probability greater 0.975, hence sufficient evidence support alternative hypothesis. Using parameters function distributional package, can extract parameters posterior distribution consists single component (.e., single normal distribution). example, can extract mean (mu) standard deviation (sigma) parameters beta posterior distribution θT\\theta_T. posterior distributions mixture normal components, can extract means standard deviations component using mix_means mix_sigmas functions, respectively. can also use parameters function extract mixture weights associated normal components posterior distribution θC\\theta_C. Lastly, calculate effective sample size posterior distribution θC\\theta_C using method Pennello Thompson (2008). , first must construct posterior distribution θC\\theta_Cwithout borrowing external control data (e.g., using vague prior).","code":"c(mean = mean(post_control),   median = median(post_control),   variance = variance(post_control)) #>        mean      median    variance  #> 0.675091383 0.675734273 0.000239683 hdr(post_control)        # 95% HDR #> <hdr[1]> #> [1] [0.6442579, 0.7052676]95 hdr(post_control, 90)    # 90% HDR #> <hdr[1]> #> [1] [0.650438, 0.7006585]90 hilo(post_control)       # 95% credible interval #> <hilo[1]> #> [1] [0.6420707, 0.7036551]95 hilo(post_control, 90)   # 90% credible interval #> <hilo[1]> #> [1] [0.6487183, 0.6992243]90 quantile(post_control, c(.025, .975))[[1]]    # 95% CrI via quantile function #> [1] 0.6420707 0.7036551 cdf(post_control, q = .7)   # Pr(theta_C < 0.7 | D) #> [1] 0.9554074 density(post_control, at = .7)                # density at 0.7 #> [1] 6.659121 density(post_control, at = .7, log = TRUE)    # log density at 0.7 #> [1] 1.895988 samp_control <- generate(x = post_control, times = 100000)[[1]] ggplot(data.frame(samp = samp_control), aes(x = samp)) +   labs(y = \"Density\", x = expression(theta[C])) +   ggtitle(expression(paste(\"Posterior Samples of \", theta[C]))) +   geom_histogram(aes(y = after_stat(density)), color = \"#5398BE\", fill = \"#5398BE\",                  position = \"identity\", binwidth = .01, alpha = 0.5) +   geom_density(color = \"black\") +   coord_cartesian(xlim = c(-0.1, 0.9)) +   theme_bw() samp_treated <- generate(x = post_treated, times = 100000)[[1]] ggplot(data.frame(samp = samp_treated), aes(x = samp)) +   labs(y = \"Density\", x = expression(theta[T])) +   ggtitle(expression(paste(\"Posterior Samples of \", theta[T]))) +   geom_histogram(aes(y = after_stat(density)), color = \"#FFA21F\", fill = \"#FFA21F\",                  position = \"identity\", binwidth = .01, alpha = 0.5) +   geom_density(color = \"black\") +   coord_cartesian(xlim = c(-0.1, 0.9)) +   theme_bw() samp_trt_diff <- samp_treated - samp_control ggplot(data.frame(samp = samp_trt_diff), aes(x = samp)) +   labs(y = \"Density\", x = expression(paste(theta[T], \" - \", theta[C]))) +   ggtitle(expression(paste(\"Posterior Samples of \", theta[T], \" - \", theta[C]))) +   geom_histogram(aes(y = after_stat(density)), color = \"#FF0000\", fill = \"#FF0000\",                  position = \"identity\", binwidth = .01, alpha = 0.5) +   geom_density(color = \"black\") +   coord_cartesian(xlim = c(-0.1, 0.9)) +   theme_bw() mean(samp_trt_diff > 0) #> [1] 0.98861 parameters(post_treated) #>          mu      sigma #> 1 0.7307423 0.01929926 mix_means(post_control)    # means of each normal component #> informative       vague  #>   0.6772442   0.6636995 mix_sigmas(post_control)   # SDs of each normal component #> informative       vague  #>  0.01361736  0.01929926 parameters(post_control)$w[[1]] #> informative       vague  #>   0.8410606   0.1589394 post_control_no_brrw <- calc_post_norm(filter(int_norm_df, trt == 0),                                        response = y,                                        prior = dist_normal(mean = mix_means(mix_prior)[\"vague\"],                                                            sd = mix_sigmas(mix_prior)[\"vague\"]),                                        internal_sd = sd_internal_control) n_int_ctrl <- nrow(filter(int_norm_df, trt == 0))   # sample size of internal control arm var_no_brrw <- variance(post_control_no_brrw)       # post variance of theta_C without borrowing var_brrw <- variance(post_control)                  # post variance of theta_C with borrowing ess <- n_int_ctrl * var_no_brrw / var_brrw          # effective sample size ess #> [1] 93.23853"},{"path":"https://gsk-biostatistics.github.io/beastt/articles/tte.html","id":"introduction-and-data-description","dir":"Articles","previous_headings":"","what":"Introduction and Data Description","title":"Time-to-Event Outcome","text":"example, illustrate use Bayesian dynamic borrowing (BDB) inclusion inverse probability weighting balance baseline covariate distributions external internal datasets. particular example considers hypothetical trial time--event outcome assume follow Weibull distribution; .e., Yi∼Weibull(α,σ)Y_i \\sim \\mbox{Weibull}(\\alpha, \\sigma) f(yi∣α,σ)=(ασ)(yiσ)α−1exp(−(yiσ)α).f(y_i \\mid \\alpha, \\sigma) = \\left( \\frac{\\alpha}{\\sigma} \\right) \\left( \\frac{y_i}{\\sigma} \\right)^{\\alpha - 1} \\exp \\left( -\\left( \\frac{y_i}{\\sigma} \\right)^\\alpha \\right). Define 𝛉={log(α),β}\\boldsymbol{\\theta} = \\{\\log(\\alpha), \\beta\\} β=−log(σ)\\beta = -\\log(\\sigma) intercept (.e., log-inverse-scale) parameter Weibull proportional hazards regression model α\\alpha shape parameter. objective use BDB IPWs construct posterior distribution probability surviving past time tt control arm, SC(t|𝛉)S_C(t | \\boldsymbol{\\theta}) (hereafter denoted SC(t)S_C(t) notational convenience). treatment arm, define prior distributions respect 𝛉\\boldsymbol{\\theta} eventually obtaining MCMC samples posterior distributions SC(t)S_C(t) ST(t)S_T(t) (.e., survival probability time tt active treatment arm). example, suppose interested survival probabilities t=12t=12 months. use simulated internal external datasets package dataset time--event response variable (observed time participant either event censored), event indicator (1: event; 0: censored), enrollment time study, total time since start study, four baseline covariates balance. external control dataset sample size 150 participants, distributions four covariates follows: - Covariate 1: normal mean standard deviation approximately 65 10, respectively - Covariate 2: binary (0 vs. 1) approximately 30% participants level 1 - Covariate 3: binary (0 vs. 1) approximately 40% participants level 1 - Covariate 4: binary (0 vs. 1) approximately 50% participants level 1 internal dataset 160 participants 80 participants control arm active treatment arms. covariate distributions arm follows: - Covariate 1: normal mean standard deviation approximately 62 8, respectively - Covariate 2: binary (0 vs. 1) approximately 40% participants level 1 - Covariate 3: binary (0 vs. 1) approximately 40% participants level 1 - Covariate 4: binary (0 vs. 1) approximately 60% participants level 1","code":"library(tibble) library(distributional) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2) library(rstan) #> Loading required package: StanHeaders #>  #> rstan version 2.32.7 (Stan version 2.32.2) #> For execution on a local, multicore CPU with excess RAM we recommend calling #> options(mc.cores = parallel::detectCores()). #> To avoid recompilation of unchanged Stan programs, we recommend calling #> rstan_options(auto_write = TRUE) #> For within-chain threading using `reduce_sum()` or `map_rect()` Stan functions, #> change `threads_per_chain` option: #> rstan_options(threads_per_chain = 1) set.seed(1234)  summary(int_tte_df) #>      subjid             y              enr_time         total_time     #>  Min.   :  1.00   Min.   : 0.7026   Min.   :0.01367   Min.   : 1.309   #>  1st Qu.: 40.75   1st Qu.: 6.4188   1st Qu.:0.83781   1st Qu.: 7.268   #>  Median : 80.50   Median :12.1179   Median :1.27502   Median :14.245   #>  Mean   : 80.50   Mean   : 9.6651   Mean   :1.19144   Mean   :15.427   #>  3rd Qu.:120.25   3rd Qu.:12.7287   3rd Qu.:1.58949   3rd Qu.:20.699   #>  Max.   :160.00   Max.   :13.9913   Max.   :1.98912   Max.   :58.644   #>      event           trt           cov1            cov2             cov3        #>  Min.   :0.00   Min.   :0.0   Min.   :46.00   Min.   :0.0000   Min.   :0.0000   #>  1st Qu.:0.00   1st Qu.:0.0   1st Qu.:57.00   1st Qu.:0.0000   1st Qu.:0.0000   #>  Median :0.00   Median :0.5   Median :62.00   Median :0.0000   Median :0.0000   #>  Mean   :0.45   Mean   :0.5   Mean   :61.83   Mean   :0.3688   Mean   :0.3625   #>  3rd Qu.:1.00   3rd Qu.:1.0   3rd Qu.:67.00   3rd Qu.:1.0000   3rd Qu.:1.0000   #>  Max.   :1.00   Max.   :1.0   Max.   :85.00   Max.   :1.0000   Max.   :1.0000   #>       cov4        #>  Min.   :0.0000   #>  1st Qu.:0.0000   #>  Median :1.0000   #>  Mean   :0.5563   #>  3rd Qu.:1.0000   #>  Max.   :1.0000 summary(ex_tte_df) #>      subjid             y               enr_time          total_time     #>  Min.   :  1.00   Min.   : 0.05804   Min.   :0.005329   Min.   : 1.191   #>  1st Qu.: 38.25   1st Qu.: 4.45983   1st Qu.:0.857692   1st Qu.: 5.782   #>  Median : 75.50   Median : 9.42004   Median :1.308708   Median :10.576   #>  Mean   : 75.50   Mean   : 8.58877   Mean   :1.232657   Mean   :12.533   #>  3rd Qu.:112.75   3rd Qu.:12.71370   3rd Qu.:1.673582   3rd Qu.:16.549   #>  Max.   :150.00   Max.   :14.00703   Max.   :1.975702   Max.   :64.793   #>      event             cov1            cov2             cov3        #>  Min.   :0.0000   Min.   :37.00   Min.   :0.0000   Min.   :0.0000   #>  1st Qu.:0.0000   1st Qu.:58.00   1st Qu.:0.0000   1st Qu.:0.0000   #>  Median :1.0000   Median :64.00   Median :0.0000   Median :0.0000   #>  Mean   :0.6267   Mean   :64.28   Mean   :0.3533   Mean   :0.4533   #>  3rd Qu.:1.0000   3rd Qu.:70.00   3rd Qu.:1.0000   3rd Qu.:1.0000   #>  Max.   :1.0000   Max.   :90.00   Max.   :1.0000   Max.   :1.0000   #>       cov4        #>  Min.   :0.0000   #>  1st Qu.:0.0000   #>  Median :0.0000   #>  Mean   :0.4733   #>  3rd Qu.:1.0000   #>  Max.   :1.0000"},{"path":"https://gsk-biostatistics.github.io/beastt/articles/tte.html","id":"propensity-scores-and-inverse-probability-weights","dir":"Articles","previous_headings":"","what":"Propensity Scores and Inverse Probability Weights","title":"Time-to-Event Outcome","text":"covariate data external internal datasets, can calculate propensity scores ATT inverse probability weights (IPWs) internal external control participants using calc_prop_scr function. creates propensity score object can use calculating approximate inverse probability weighted power prior next step. Note: reading external internal datasets calc_prop_scr, sure include arms want balance covariate distributions (typically internal external control arms). example, want balance covariate distributions external control arm similar internal control arm, exclude internal active treatment arm data function. order check suitability external data, can create variety diagnostic plots. first plot might want histogram overlapping propensity score distributions datasets. get , use prop_scr_hist function. function takes propensity score object made previous step, can optionally supply variable want look (either propensity score IPW). default, plot propensity scores. Additionally, can look densities rather histograms using prop_scr_dens function. looking IPWs either histogram density functions, important note IPWs external control participants shown ATT IPWs internal control participants equal 1.   final plot might want look love plot visualize absolute standardized mean differences (unadjusted adjusted IPWs) covariates internal external data. , use prop_scr_love function. Like previous function, required parameter function propensity score object, can also provide location along x-axis vertical reference line.","code":"ps_obj <- calc_prop_scr(internal_df = filter(int_tte_df, trt == 0),                         external_df = ex_tte_df,                         id_col = subjid,                         model = ~ cov1 + cov2 + cov3 + cov4) ps_obj #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> • cov1 + cov2 + cov3 + cov4 #>  #> ── Propensity Scores and Weights ─────────────────────────────────────────────── #> • Effective sample size of the external arm: 81 #> # A tibble: 150 × 4 #>    subjid Internal `Propensity Score` `Inverse Probability Weight` #>     <int> <lgl>                 <dbl>                        <dbl> #>  1      1 FALSE                 0.333                        0.500 #>  2      2 FALSE                 0.288                        0.405 #>  3      3 FALSE                 0.539                        1.17  #>  4      4 FALSE                 0.546                        1.20  #>  5      5 FALSE                 0.344                        0.524 #>  6      6 FALSE                 0.393                        0.646 #>  7      7 FALSE                 0.390                        0.639 #>  8      8 FALSE                 0.340                        0.515 #>  9      9 FALSE                 0.227                        0.294 #> 10     10 FALSE                 0.280                        0.389 #> # ℹ 140 more rows #>  #> ── Absolute Standardized Mean Difference ─────────────────────────────────────── #> # A tibble: 4 × 3 #>   covariate diff_unadj diff_adj #>   <chr>          <dbl>    <dbl> #> 1 cov1          0.339  0.0461   #> 2 cov2          0.0450 0.0204   #> 3 cov3          0.160  0.000791 #> 4 cov4          0.308  0.00857 prop_scr_hist(ps_obj) prop_scr_dens(ps_obj, variable = \"ipw\") prop_scr_love(ps_obj, reference_line = 0.1)"},{"path":"https://gsk-biostatistics.github.io/beastt/articles/tte.html","id":"approximate-inverse-probability-weighted-power-prior","dir":"Articles","previous_headings":"","what":"Approximate Inverse Probability Weighted Power Prior","title":"Time-to-Event Outcome","text":"Now created assessed propensity score object, can read calc_power_prior_weibull function calculate approximate inverse probability weighted power prior 𝛉\\boldsymbol{\\theta} control arm, denote 𝛉C={log(αC),βC}\\boldsymbol{\\theta}_C = \\{\\log(\\alpha_C), \\beta_C\\}. Specifically, approximate power prior bivariate normal distribution using one two approximation methods: (1) Laplace approximation (2) estimation mean vector covariance matrix using MCMC samples unnormalized power prior (see details section calc_power_prior_weibull documentation information). example, use Laplace approximation considerably faster MCMC approach. approximate power prior, need supply following information: weighted object (propensity score object created ) response variable name (case yy) event indicator variable name (case eventevent) initial prior intercept parameter, form normal distributional object (e.g., N(0,sd=10)\\mbox{N}(0, \\mbox{sd} = 10)) scale hyperparameter half-normal initial prior shape parameter approximation method (either “Laplace” “MCMC”)","code":"pwr_prior <- calc_power_prior_weibull(ps_obj,                                       response = y,                                       event = event,                                       intercept = dist_normal(0, 10),                                       shape = 50,                                       approximation = \"Laplace\") plot_dist(pwr_prior)"},{"path":"https://gsk-biostatistics.github.io/beastt/articles/tte.html","id":"inverse-probability-weighted-robust-mixture-prior","dir":"Articles","previous_headings":"","what":"Inverse Probability Weighted Robust Mixture Prior","title":"Time-to-Event Outcome","text":"can robustify approximate multivariate normal (MVN) power prior 𝛉C\\boldsymbol{\\theta}_C adding vague component create robust mixture prior (RMP). define vague component MVN distribution mean vector approximate power prior covariance matrix equal covariance matrix approximate power prior multiplied rexr_{ex}, rexr_{ex} denotes number observed events external control arm. construct RMP, can use either robustify_norm robustify_mvnorm functions, place 0.5 weight component. two components resulting RMP labeled “informative” “vague”. can print mean vectors covariance matrices MVN component using functions mix_means mix_sigmas, respectively.","code":"r_external <- sum(ex_tte_df$event)   # number of observed events mix_prior <- robustify_mvnorm(pwr_prior, r_external, weights = c(0.5, 0.5))   # RMP mix_means(mix_prior)     # mean vectors #> $informative #> [1]  0.2940907 -2.5655689 #>  #> $vague #> [1]  0.2940907 -2.5655689 mix_sigmas(mix_prior)    # mean covariance matrices #> $informative #>             [,1]        [,2] #> [1,] 0.016251652 0.003325476 #> [2,] 0.003325476 0.011868788 #>  #> $vague #>           [,1]      [,2] #> [1,] 1.5276553 0.3125948 #> [2,] 0.3125948 1.1156660 #plot_dist(mix_prior)"},{"path":"https://gsk-biostatistics.github.io/beastt/articles/tte.html","id":"posterior-distributions","dir":"Articles","previous_headings":"","what":"Posterior Distributions","title":"Time-to-Event Outcome","text":"create posterior distribution 𝛉C\\boldsymbol{\\theta}_C, can pass resulting RMP internal control data calc_post_weibull function returns stanfit object can extract MCMC samples control parameters. addition returning posterior samples log(αC)\\log(\\alpha_C) βC\\beta_C, function returns posterior samples marginal survival probability SC(t)S_C(t) time(s) tt can specified either scalar vector numbers using analysis_time argument. Note: reading internal data directly calc_post_weibull, sure include arm interest (e.g., internal control arm creating posterior distribution 𝛉C\\boldsymbol{\\theta}_C). can extract plot posterior samples SC(t)S_C(t). , plot samples using histogram, however, additional posterior plots (e.g., density curves, trace plots) can easily obtained using bayesplot package.  Next, create posterior distribution survival probability ST(t)S_T(t) active treatment arm time t=12t=12 reading internal data corresponding arm calc_post_weibull function. case, use vague component RMP MVN prior. noted earlier, sure read data internal active treatment arm excluding internal control data. previously done, can extract plot posterior samples ST(t)S_T(t).  define marginal treatment effect difference survival probabilities 12 months active treatment control arms (.e., ST(t=12)−SC(t=12)S_T(t=12) - S_C(t=12)). can obtain sample posterior distribution ST(t=12)−SC(t=12)S_T(t=12) - S_C(t=12) subtracting posterior sample SC(t=12)S_C(t=12) posterior sample ST(t=12)S_T(t=12).","code":"post_control <- calc_post_weibull(filter(int_tte_df, trt == 0),                                   response = y,                                   event = event,                                   prior = mix_prior,                                   analysis_time = 12) summary(post_control)$summary #>                     mean      se_mean         sd         2.5%          25% #> beta0         -2.6887252 0.0007416549 0.08973077   -2.8896461   -2.7388799 #> log_alpha      0.3621925 0.0007810625 0.10469515    0.1575300    0.2930159 #> alpha          1.4444037 0.0011479498 0.15277470    1.1706159    1.3404641 #> survProb[1]    0.4730793 0.0003307721 0.04382526    0.3949843    0.4439155 #> lp__        -148.4751404 0.0118123153 1.15276979 -151.6658488 -148.8919240 #>                     50%          75%        97.5%     n_eff      Rhat #> beta0         -2.682493   -2.6292044   -2.5358069 14637.910 1.0000966 #> log_alpha      0.361368    0.4291120    0.5731935 17967.248 0.9999709 #> alpha          1.435292    1.5358930    1.7739230 17711.572 0.9999736 #> survProb[1]    0.470524    0.4987585    0.5702913 17554.608 1.0001324 #> lp__        -148.108591 -147.6609827 -147.3811442  9523.906 0.9999708 #plot_dist(post_control) surv_prob_control <- as.data.frame(extract(post_control, pars = c(\"survProb\")))[,1] ggplot(data.frame(samp = surv_prob_control), aes(x = samp)) +   labs(y = \"Density\", x = expression(paste(S[C], \"(t=12)\"))) +   ggtitle(expression(paste(\"Posterior Samples of \", S[C], \"(t=12)\"))) +   geom_histogram(aes(y = after_stat(density)), color = \"#5398BE\", fill = \"#5398BE\",                  position = \"identity\", binwidth = .01, alpha = 0.5) +   geom_density(color = \"black\") +   coord_cartesian(xlim = c(-0.2, 0.8)) +   theme_bw() vague_prior <- dist_multivariate_normal(mu = list(mix_means(mix_prior)[[2]]),                                         sigma = list(mix_sigmas(mix_prior)[[2]])) post_treated <- calc_post_weibull(filter(int_tte_df, trt == 1),                                   response = y,                                   event = event,                                   prior = vague_prior,                                   analysis_time = 12) summary(post_treated)$summary #>                     mean      se_mean         sd          2.5%          25% #> beta0         -2.9467394 0.0014810376 0.14726947   -3.26991147   -3.0353030 #> log_alpha      0.3526892 0.0015533881 0.15956920    0.02989851    0.2470030 #> alpha          1.4409985 0.0022038801 0.22910480    1.03034996    1.2801829 #> survProb[1]    0.5903455 0.0003800737 0.05223538    0.48591817    0.5548152 #> lp__        -141.7011034 0.0098800342 1.02027824 -144.47671402 -142.0942676 #>                      50%          75%        97.5%     n_eff      Rhat #> beta0         -2.9322638   -2.8440318   -2.6968268  9887.653 0.9999780 #> log_alpha      0.3568371    0.4618120    0.6563501 10552.082 0.9999734 #> alpha          1.4288031    1.5869469    1.9277434 10806.684 0.9999703 #> survProb[1]    0.5911443    0.6259527    0.6894547 18888.340 1.0000317 #> lp__        -141.3906390 -140.9749554 -140.7038264 10664.005 0.9999849 #plot_dist(post_treated) surv_prob_treated <- as.data.frame(extract(post_treated, pars = c(\"survProb\")))[,1] ggplot(data.frame(samp = surv_prob_treated), aes(x = samp)) +   labs(y = \"Density\", x = expression(paste(S[T], \"(t=12)\"))) +   ggtitle(expression(paste(\"Posterior Samples of \", S[T], \"(t=12)\"))) +   geom_histogram(aes(y = after_stat(density)), color = \"#FFA21F\", fill = \"#FFA21F\",                  position = \"identity\", binwidth = .01, alpha = 0.5) +   geom_density(color = \"black\") +   coord_cartesian(xlim = c(-0.2, 0.8)) +   theme_bw() samp_trt_diff <- surv_prob_treated - surv_prob_control ggplot(data.frame(samp = samp_trt_diff), aes(x = samp)) +   labs(y = \"Density\", x = expression(paste(S[T], \"(t=12) - \", S[C], \"(t=12)\"))) +   ggtitle(expression(paste(\"Posterior Samples of \", S[T],                            \"(t=12) - \", S[C], \"(t=12)\"))) +   geom_histogram(aes(y = after_stat(density)), color = \"#FF0000\", fill = \"#FF0000\",                  position = \"identity\", binwidth = .01, alpha = 0.5) +   geom_density(color = \"black\") +   coord_cartesian(xlim = c(-0.2, 0.8)) +   theme_bw()"},{"path":"https://gsk-biostatistics.github.io/beastt/articles/tte.html","id":"posterior-summary-statistics","dir":"Articles","previous_headings":"","what":"Posterior Summary Statistics","title":"Time-to-Event Outcome","text":"Suppose want test hypotheses H0:ST(t=12)−SC(t=12)≤0H_0: S_T(t=12) - S_C(t=12) \\le 0 versus H1:ST(t=12)−SC(t=12)>0H_1: S_T(t=12) - S_C(t=12) > 0. can use posterior sample ST(t=12)−SC(t=12)S_T(t=12) - S_C(t=12) calculate posterior probability Pr(ST(t=12)−SC(t=12)>0∣D)Pr(S_T(t=12) - S_C(t=12) > 0 \\mid D) (.e., probability favor H1H_1), conclude sufficient evidence favor alternative hypothesis Pr(ST(t=12)−SC(t=12)>0∣D)>0.975Pr(S_T(t=12) - S_C(t=12) > 0 \\mid D) > 0.975. see posterior probability less 0.975, hence sufficient evidence support alternative hypothesis. MCMC samples posterior distributions, can calculate posterior summary statistics mean, median, standard deviation. example, calculate statistics using posterior distribution ST(t=12)−SC(t=12)S_T(t=12) - S_C(t=12). can also calculate credible intervals using quantile function. Lastly, calculate effective sample size posterior distribution SC(t=12)S_C(t=12) using method Pennello Thompson (2008). , first must construct posterior distribution SC(t=12)S_C(t=12)without borrowing external control data (e.g., using vague prior).","code":"mean(samp_trt_diff > 0) #> [1] 0.9534667 c(mean = mean(samp_trt_diff),   median = median(samp_trt_diff),   SD = sd(samp_trt_diff)) #>       mean     median         SD  #> 0.11726619 0.11920218 0.06795424 quantile(samp_trt_diff, c(.025, .975))    # 95% CrI #>        2.5%       97.5%  #> -0.02240224  0.24521556 post_ctrl_no_brrw <- calc_post_weibull(filter(int_tte_df, trt == 0),                                        response = y,                                        event = event,                                        prior = vague_prior,                                        analysis_time = 12) surv_prob_ctrl_nb <- as.data.frame(extract(post_ctrl_no_brrw, pars = c(\"survProb\")))[,1] n_int_ctrl <- nrow(filter(int_tte_df, trt == 0))  # sample size of internal control arm var_no_brrw <- var(surv_prob_ctrl_nb)             # post variance of S_C(t) without borrowing var_brrw <- var(surv_prob_control)                # post variance of S_C(t) with borrowing ess <- n_int_ctrl * var_no_brrw / var_brrw        # effective sample size ess #> [1] 123.4881"},{"path":"https://gsk-biostatistics.github.io/beastt/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Christina Fillmore. Author, maintainer. Ben Arancibia. Author. Nate Bean. Author. Abi Terry. Author. GlaxoSmithKline Research & Development Limited. Copyright holder, funder. Trustees Columbia University. Copyright holder.           R/stanmodels.R, configure, configure.win","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Fillmore C, Arancibia B, Bean N, Terry (2025). beastt: Bayesian Evaluation, Analysis, Simulation Software Tools Trials. R package version 0.0.3, https://github.com/GSK-Biostatistics/beastt, https://gsk-biostatistics.github.io/beastt/.","code":"@Manual{,   title = {beastt: Bayesian Evaluation, Analysis, and Simulation Software Tools for Trials},   author = {Christina Fillmore and Ben Arancibia and Nate Bean and Abi Terry},   year = {2025},   note = {R package version 0.0.3, https://github.com/GSK-Biostatistics/beastt},   url = {https://gsk-biostatistics.github.io/beastt/}, }"},{"path":[]},{"path":[]},{"path":"https://gsk-biostatistics.github.io/beastt/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Bayesian Evaluation, Analysis, and Simulation Software Tools for Trials","text":"Welcome {beastt} package! R package designed assist users performing Bayesian dynamic borrowing covariate adjustment via inverse probability weighted robust mixture priors simulations data analyses clinical trials. sake package, use term IPW BMB refer inverse probability weighted robust mixture methodology.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/index.html","id":"what-is-ipw-bdb","dir":"","previous_headings":"","what":"What is IPW BDB?","title":"Bayesian Evaluation, Analysis, and Simulation Software Tools for Trials","text":"Inverse Probability Weighted Bayesian Dynamic Borrowing (IPW BDB) statistical approach designed enhance estimation marginal (.e., population-averaged unconditional) treatment effects clinical trials. method employs inverse probability weighted robust mixture priors adjust covariate differences new internal study external (.e., historical) control data.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/index.html","id":"why-use-ipw-bdb","dir":"","previous_headings":"","what":"Why use IPW BDB?","title":"Bayesian Evaluation, Analysis, and Simulation Software Tools for Trials","text":"using propensity score-based inverse probability weighting, IPW BDB effectively balances prognostic variables trial participants historical controls, improving inference accuracy reducing biases due differences covariate distributions. technique increases statistical power reduces potential biases estimating average treatment effects, critical health policy decisions drug approval processes. IPW BDB two mechanisms can account drift different sources: 1. use robust mixture prior alleviates prior-data conflict dynamically weighting external data significant level drift studies. 2. Inverse probability weighting can account explainable causes drift balancing covariate distributions external internal control participants. Augmenting standard robust mixture prior (RMP) approach incorporate IPWs add substantial computational burden associated Bayesian approaches; e.g., cases conjugate priors exist standard RMP approach, still exist IPW BDB approach.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/index.html","id":"when-can-ipw-bdb-be-used","dir":"","previous_headings":"","what":"When can IPW BDB be used?","title":"Bayesian Evaluation, Analysis, and Simulation Software Tools for Trials","text":"IPW BDB considered clinical trial settings individual level external control data available want integrate data current trial. method particularly useful differences distributions key prognostic factors current study population external controls, otherwise introduce bias. especially relevant oncology rare disease trials, using external data can help overcome challenges slow patient enrollment due reluctance join control groups. IPW BDB well-suited contexts Bayesian dynamic borrowing already applicable benefit additional adjustments confounding.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Bayesian Evaluation, Analysis, and Simulation Software Tools for Trials","text":"can install development version {beastt} GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"GSK-Biostatistics/beastt\")"},{"path":"https://gsk-biostatistics.github.io/beastt/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Bayesian Evaluation, Analysis, and Simulation Software Tools for Trials","text":"moment {beastt} covers borrowing external control data normal, binary, time event endpoints. information, see vignettes.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Bayesian Evaluation, Analysis, and Simulation Software Tools for Trials","text":"Feel free contribute {beastt} package reporting issues submitting pull requests GitHub repository.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Bayesian Evaluation, Analysis, and Simulation Software Tools for Trials","text":"package released GLP-3.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/beastt-package.html","id":null,"dir":"Reference","previous_headings":"","what":"The 'beastt' package. — beastt-package","title":"The 'beastt' package. — beastt-package","text":"Inverse Probability Weighted Bayesian Dynamic Borrowing","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/beastt-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The 'beastt' package. — beastt-package","text":"Stan Development Team (NA). RStan: R interface Stan. R package version 2.32.3. https://mc-stan.org","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/bootstrap_cov.html","id":null,"dir":"Reference","previous_headings":"","what":"Bootstrap Covariate Data — bootstrap_cov","title":"Bootstrap Covariate Data — bootstrap_cov","text":"Bootstrap Covariate Data","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/bootstrap_cov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bootstrap Covariate Data — bootstrap_cov","text":"","code":"bootstrap_cov(   external_dat,   n,   imbal_var = NULL,   imbal_prop = NULL,   ref_val = 0 )"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/bootstrap_cov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bootstrap Covariate Data — bootstrap_cov","text":"external_dat Data frame external data bootstrap covariate vectors n Number rows output dataset imbal_var Optional variable indicating covariate's distribution altered incorporate imbalance compared external data. left NULL, distributions covariates output dataset match distributions external dataset. imbalance variable must binary. imbal_prop Optional imbalance proportion, required imbalance variable specified. defines proportion individuals reference value imbalance variable returned dataset. can either single proportion vector proportions, case list datasets returned. ref_val Optional value corresponding reference level binary imbalance variable, specified","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/bootstrap_cov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bootstrap Covariate Data — bootstrap_cov","text":"Data frame number columns external data frame n number rows (length imbal_prop 0 1); otherwise, list data frames length equal imbal_prop","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/bootstrap_cov.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bootstrap Covariate Data — bootstrap_cov","text":"Covariate data can generated n individuals enrolled internal trial bootstrap sampling entire covariate vectors external data, thus preserving correlation covariates. imbal_var = NULL imbal_prop = NULL, function returns single data frame distributions covariate align covariate distributions external data (.e., balanced covariate distributions across two trials). Alternatively, covariate imbalance can incorporated generated sample respect binary covariate (imbal_var) specified proportion (imbal_prop) individuals resulting sample reference level (ref_val) imbalance covariate. case, stratified bootstrap sampling employed imbalance covariate stratification factor. Multiple samples varying degrees imbalance can generated simultaneously defining imbal_prop vector values. function returns list data frames length equal number specified imbalance proportions.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/bootstrap_cov.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bootstrap Covariate Data — bootstrap_cov","text":"","code":"# Return one data frame with covariate distributions similar to external data samp_balance <- bootstrap_cov(ex_binary_df, n = 1000)  # Return a list of two data frames that incorporate imbalance w.r.t. covariate 2 samp_imbalance <- bootstrap_cov(ex_binary_df, n = 1000, imbal_var = cov2,                                 imbal_prop = c(0.25, 0.5), ref_val = 0)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_cond_binary.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Conditional Drift and Treatment Effect for Binary Outcome Models — calc_cond_binary","title":"Calculate Conditional Drift and Treatment Effect for Binary Outcome Models — calc_cond_binary","text":"order properly generate binary response data internal trial part simulation study investigates inverse probability weighting, need translate desired marginal drift treatment effect corresponding conditional drift treatment effect can added binary outcome model (e.g., logistic regression model) used simulate response data.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_cond_binary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Conditional Drift and Treatment Effect for Binary Outcome Models — calc_cond_binary","text":"","code":"calc_cond_binary(population, glm, marg_drift, marg_trt_eff)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_cond_binary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Conditional Drift and Treatment Effect for Binary Outcome Models — calc_cond_binary","text":"population large data frame (e.g., number rows \\(\\ge\\) 100,000) columns correspond covariates defined logistic regression model object. data frame constructed represent population internal trial according assumed covariate distributions (possibly imbalanced external data). glm Logistic regression model object fit using external data marg_drift Vector marginal drift values marg_trt_eff Vector marginal treatment effect values","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_cond_binary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Conditional Drift and Treatment Effect for Binary Outcome Models — calc_cond_binary","text":"tibble combinations marginal drift treatment effect. row conditional drift treatment effect calculated well true control response rate true treatment effect.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_cond_binary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Conditional Drift and Treatment Effect for Binary Outcome Models — calc_cond_binary","text":"simulation studies investigate properties inverse probability weighted Bayesian dynamic borrowing, scenarios considered underlying response rates internal external control populations differ varying amounts due unmeasured confounding (.e., drift, positive values indicate higher response rate internal population). values drift treatment effect (.e., risk difference) can defined marginal scale simulation studies, must first convert values conditional scale include terms, along covariates, logistic regression outcome model generating response data internal arms. allows us assume relationship covariates response variable properly accounting drift treatment effect. identify conditional drift treatment effect correspond specified values marginal drift treatment effect, first bootstrap covariate vectors external data (e.g., \\(N \\ge 100,000\\)) construct \"population\" represents internal trial (possibly incorporating intentional covariate imbalance) external trial standardizing match covariate distributions internal trial (allowing us control measured confounding potential imbalance covariate distributions). Measured confounding can incorporated data generation bootstrapping large data frame (population) distribution least one covariate intentionally varied external data; additional unmeasured drift can incorporated translation specified marginal values (marg_drift) conditional values. Let \\(\\Delta\\) \\(\\delta\\) denote marginal conditional drift, respectively. specified value \\(\\Delta\\), can identify corresponding \\(\\delta\\) value , added additional term logistic regression model (.e., change intercept) individual population, increases/decreases population-averaged conditional probabilities response amount approximately equal \\(\\Delta\\). , optimal \\(\\delta\\) minimizes $$\\left| \\left( \\frac{1}{N} \\sum_{=1}^N \\frac{\\exp \\left(   \\boldsymbol{x}_i^\\prime \\boldsymbol{\\beta}_{EC} + \\delta \\right)}{1 +   \\exp\\left(\\boldsymbol{x}_i^\\prime \\boldsymbol{\\beta}_{EC} + \\delta \\right)}   - \\frac{1}{N} \\sum_{=1}^N \\frac{\\exp \\left(   \\boldsymbol{x}_i^\\prime \\boldsymbol{\\beta}_{EC} \\right)}{1 +   \\exp \\left(\\boldsymbol{x}_i^\\prime \\boldsymbol{\\beta}_{EC} \\right)}   \\right) - \\Delta \\right|,$$ \\(\\boldsymbol{\\beta}_{EC}\\) vector regression coefficients logistic regression model (glm) fit external control data (assumed \"true\" covariate effects generating response data) \\(\\boldsymbol{x}_i\\) vector covariates bootstrapped population size \\(N\\). formula , first second terms correspond population-averaged conditional probabilities (.e., marginal response rates) internal control population drift external control population (covariate distributions standardized match internal trial), respectively. now denote marginal conditional treatment effect \\(\\Gamma\\) \\(\\gamma\\), respectively, can use similar process identify optimal \\(\\gamma\\) approximately corresponds specified value \\(\\Gamma\\), done minimizing following: $$\\left| \\left( \\frac{1}{N} \\sum_{=1}^N \\frac{\\exp \\left(   \\boldsymbol{x}_i^\\prime \\boldsymbol{\\beta}_{EC} + \\delta + \\gamma \\right)}{1 +   \\exp\\left(\\boldsymbol{x}_i^\\prime \\boldsymbol{\\beta}_{EC} + \\delta + \\gamma \\right)}   - \\frac{1}{N} \\sum_{=1}^N \\frac{\\exp \\left(   \\boldsymbol{x}_i^\\prime \\boldsymbol{\\beta}_{EC} + \\delta \\right)}{1 +   \\exp \\left(\\boldsymbol{x}_i^\\prime \\boldsymbol{\\beta}_{EC} + \\delta \\right)}   \\right) - \\Gamma \\right|,$$ first term population-averaged conditional probabilities (.e., marginal response rate) internal treated population.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_cond_binary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Conditional Drift and Treatment Effect for Binary Outcome Models — calc_cond_binary","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union # Model \"true\" regression coefficients using the external data logit_mod <- glm(y ~ cov1 + cov2 + cov3 + cov4, data = ex_binary_df, family = binomial)  # Bootstrap internal control \"population\" with imbalance w.r.t. covariate 2 pop_int_ctrl <- bootstrap_cov(ex_binary_df, n = 100000, imbal_var = cov2,                               imbal_prop = 0.25, ref_val = 0) |>                               select(-subjid, -y)  # keep only covariate columns  # Convert the marginal drift and treatment effects to conditional calc_cond_binary(population = pop_int_ctrl, glm = logit_mod,                  marg_drift = c(-.1, 0, .1), marg_trt_eff = c(0, .15)) #> # A tibble: 6 × 6 #>   marg_drift marg_trt_eff conditional_drift true_control_RR conditional_trt_eff #>        <dbl>        <dbl>             <dbl>           <dbl>               <dbl> #> 1       -0.1         0               -0.413           0.446               0     #> 2       -0.1         0.15            -0.413           0.446               0.623 #> 3        0           0                0               0.546               0     #> 4        0           0.15             0               0.546               0.660 #> 5        0.1         0                0.428           0.646               0     #> 6        0.1         0.15             0.428           0.646               0.776 #> # ℹ 1 more variable: true_trt_RR <dbl>"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_beta.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Posterior Beta — calc_post_beta","title":"Calculate Posterior Beta — calc_post_beta","text":"Calculate posterior distribution beta (mixture beta components). relevant treatment arms internal dataset read (e.g., control arm constructing posterior distribution control response rate).","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_beta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Posterior Beta — calc_post_beta","text":"","code":"calc_post_beta(internal_data, response, prior)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_beta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Posterior Beta — calc_post_beta","text":"internal_data tibble internal data. response Name response variable prior distributional object corresponding beta distribution mixture distribution beta components","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_beta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Posterior Beta — calc_post_beta","text":"distributional object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_beta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Posterior Beta — calc_post_beta","text":"given arm internal trial (e.g., control arm active treatment arm) size \\(N_I\\), suppose response data binary \\(Y_i \\sim \\mbox{Bernoulli}(\\theta)\\), \\(=1,\\ldots,N_I\\). posterior distribution \\(\\theta\\) written $$\\pi( \\theta \\mid \\boldsymbol{y} ) \\propto \\mathcal{L}(\\theta \\mid \\boldsymbol{y}) \\; \\pi(\\theta),$$ \\(\\mathcal{L}(\\theta \\mid \\boldsymbol{y})\\) likelihood response data internal arm \\(\\pi(\\theta)\\) prior distribution \\(\\theta\\) (either beta distribution mixture distribution arbitrary number beta components). posterior distribution \\(\\theta\\) either beta distribution mixture beta components depending whether prior single beta distribution mixture distribution.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_beta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Posterior Beta — calc_post_beta","text":"","code":"library(dplyr) library(distributional) calc_post_beta(internal_data = filter(int_binary_df, trt == 1),                response = y,                prior = dist_beta(0.5, 0.5)) #> <distribution[1]> #> [1] Beta(62, 20)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Posterior Normal — calc_post_norm","title":"Calculate Posterior Normal — calc_post_norm","text":"Calculate posterior distribution normal (mixture normal components). relevant treatment arms internal dataset read (e.g., control arm constructing posterior distribution control mean).","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Posterior Normal — calc_post_norm","text":"","code":"calc_post_norm(internal_data, response, prior, internal_sd = NULL)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Posterior Normal — calc_post_norm","text":"internal_data tibble internal data. response Name response variable prior distributional object corresponding normal distribution, t distribution, mixture distribution normal /t components internal_sd Standard deviation internal response data assumed known. can left NULL assumed unknown","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Posterior Normal — calc_post_norm","text":"distributional object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_norm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Posterior Normal — calc_post_norm","text":"given arm internal trial (e.g., control arm active treatment arm) size \\(N_I\\), suppose response data normally distributed \\(Y_i \\sim N(\\theta, \\sigma_I^2)\\), \\(=1,\\ldots,N_I\\). \\(\\sigma_I^2\\) assumed known, posterior distribution \\(\\theta\\) written $$\\pi( \\theta \\mid \\boldsymbol{y}, \\sigma_{}^2 ) \\propto \\mathcal{L}(\\theta \\mid \\boldsymbol{y}, \\sigma_{}^2) \\; \\pi(\\theta),$$ \\(\\mathcal{L}(\\theta \\mid \\boldsymbol{y}, \\sigma_{}^2)\\) likelihood response data internal arm \\(\\pi(\\theta)\\) prior distribution \\(\\theta\\) (either normal distribution, \\(t\\) distribution, mixture distribution arbitrary number normal /\\(t\\) components). \\(t\\) components prior \\(\\theta\\) approximated mixture two normal distributions. \\(\\sigma_I^2\\) unknown, marginal posterior distribution \\(\\theta\\) instead written $$\\pi( \\theta \\mid \\boldsymbol{y} ) \\propto \\left\\{ \\int_0^\\infty \\mathcal{L}(\\theta, \\sigma_{}^2 \\mid \\boldsymbol{y}) \\; \\pi(\\sigma_{}^2) \\; d\\sigma_{}^2 \\right\\} \\times \\pi(\\theta).$$ case, prior \\(\\sigma_I^2\\) chosen \\(\\pi(\\sigma_{}^2) = (\\sigma_I^2)^{-1}\\) \\(\\left\\{ \\int_0^\\infty \\mathcal{L}(\\theta, \\sigma_{}^2 \\mid \\boldsymbol{y}) \\; \\pi(\\sigma_{}^2) \\; d\\sigma_{}^2 \\right\\}\\) becomes non-standardized \\(t\\) distribution. integrated likelihood approximated mixture two normal distributions. internal_sd supplied positive value prior corresponds single normal distribution, posterior distribution \\(\\theta\\) normal distribution. internal_sd = NULL types prior distributions specified (e.g., mixture t distribution), posterior distribution mixture normal distributions.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Posterior Normal — calc_post_norm","text":"","code":"library(distributional) library(dplyr) post_treated <- calc_post_norm(internal_data = filter(int_norm_df, trt == 1),                                response = y,                                prior = dist_normal(50, 10),                                internal_sd = 0.15)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_weibull.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Posterior Weibull — calc_post_weibull","title":"Calculate Posterior Weibull — calc_post_weibull","text":"Calculate posterior distribution probability surviving past given analysis time(s) time--event data Weibull likelihood. relevant treatment arms internal dataset read (e.g., control arm constructing posterior distribution control survival probability).","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_weibull.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Posterior Weibull — calc_post_weibull","text":"","code":"calc_post_weibull(internal_data, response, event, prior, analysis_time, ...)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_weibull.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Posterior Weibull — calc_post_weibull","text":"internal_data can either propensity score object tibble internal data. response Name response variable event Name event indicator variable (1: event; 0: censored) prior distributional object corresponding multivariate normal distribution mixture 2 multivariate normals. first element mean vector first row/column covariance matrix correspond log-shape parameter, second element corresponds intercept (.e., log-inverse-scale) parameter. analysis_time Vector time(s) survival probabilities calculated ... rstan sampling option. overrides default options. information, see rstan::sampling()","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_weibull.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Posterior Weibull — calc_post_weibull","text":"stan posterior object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_weibull.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Posterior Weibull — calc_post_weibull","text":"given arm internal trial (e.g., control arm active treatment arm) size \\(N_I\\), suppose response data time event \\(Y_i \\sim \\mbox{Weibull}(\\alpha, \\sigma)\\), $$f(y_i \\mid \\alpha, \\sigma) = \\left( \\frac{\\alpha}{\\sigma} \\right) \\left( \\frac{y_i}{\\sigma}   \\right)^{\\alpha - 1} \\exp \\left( -\\left( \\frac{y_i}{\\sigma} \\right)^\\alpha   \\right),$$ \\(=1,\\ldots,N_I\\). Define \\(\\boldsymbol{\\theta} = \\{\\log(\\alpha), \\beta\\}\\) \\(\\beta = -\\log(\\sigma)\\) intercept parameter Weibull proportional hazards regression model. posterior distribution \\(\\boldsymbol{\\theta}\\) written $$\\pi( \\boldsymbol{\\theta} \\mid \\boldsymbol{y}, \\boldsymbol{\\nu} ) \\propto   \\mathcal{L}(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}, \\boldsymbol{\\nu}) \\;   \\pi(\\boldsymbol{\\theta}),$$ \\(\\mathcal{L}(\\boldsymbol{\\theta} \\mid \\boldsymbol{y}, \\boldsymbol{\\nu}) =   \\prod_{=1}^{N_I} f(y_i \\mid \\boldsymbol{\\theta})^{\\nu_i} S(y_i \\mid \\boldsymbol{\\theta})^{1 - \\nu_i}\\) likelihood response data internal arm event indicator \\(\\boldsymbol{\\nu}\\) survival function \\(S(y_i \\mid \\boldsymbol{\\theta}) =   1 - F(y_i \\mid \\boldsymbol{\\theta})\\), \\(\\pi(\\boldsymbol{\\theta})\\) prior distribution \\(\\boldsymbol{\\theta}\\) (either multivariate normal distribution mixture two multivariate normal distributions). Note posterior distribution \\(\\boldsymbol{\\theta}\\) closed form, thus MCMC samples \\(\\log(\\alpha)\\) \\(\\beta\\) drawn posterior. MCMC samples used construct samples posterior distribution probability surviving past specified analysis time(s) given arm. construct posterior distribution treatment difference (.e., difference survival probabilities specified analysis time), obtain MCMC samples posterior distributions survival probabilities arm subtract control-arm samples treatment-arm samples.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_post_weibull.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Posterior Weibull — calc_post_weibull","text":"","code":"library(distributional) library(dplyr) library(rstan) #> Loading required package: StanHeaders #>  #> rstan version 2.32.7 (Stan version 2.32.2) #> For execution on a local, multicore CPU with excess RAM we recommend calling #> options(mc.cores = parallel::detectCores()). #> To avoid recompilation of unchanged Stan programs, we recommend calling #> rstan_options(auto_write = TRUE) #> For within-chain threading using `reduce_sum()` or `map_rect()` Stan functions, #> change `threads_per_chain` option: #> rstan_options(threads_per_chain = 1) mvn_prior <- dist_multivariate_normal(    mu = list(c(0.3, -2.6)),    sigma = list(matrix(c(1.5, 0.3, 0.3, 1.1), nrow = 2))) post_treated <- calc_post_weibull(filter(int_tte_df, trt == 1),                                   response = y,                                   event = event,                                   prior = mvn_prior,                                   analysis_time = 12,                                   warmup = 5000,                                   iter = 15000) # Extract MCMC samples of survival probabilities at time t=12 surv_prob_treated <- as.data.frame(extract(post_treated,                                    pars = c(\"survProb\")))[,1]"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_beta.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Power Prior Beta — calc_power_prior_beta","title":"Calculate Power Prior Beta — calc_power_prior_beta","text":"Calculate (potentially inverse probability weighted) beta power prior control response rate using external control data.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_beta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Power Prior Beta — calc_power_prior_beta","text":"","code":"calc_power_prior_beta(external_data, response, prior)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_beta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Power Prior Beta — calc_power_prior_beta","text":"external_data can either prop_scr_obj created calling create_prop_scr() tibble external data. just tibble weights assumed 1. response Name response variable prior beta distributional object initial prior control response rate external control data observed","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_beta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Power Prior Beta — calc_power_prior_beta","text":"Beta power prior object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_beta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Power Prior Beta — calc_power_prior_beta","text":"Weighted participant-level response data control arm external study incorporated inverse probability weighted (IPW) power prior control response rate \\(\\theta_C\\). borrowing information external control arm size \\(N_{EC}\\), components IPW power prior \\(\\theta_C\\) defined follows: Initial prior: $$\\theta_C \\sim \\mbox{Beta}(\\nu_0, \\phi_0)$$ IPW likelihood external response data \\(\\boldsymbol{y}_E\\) weights \\(\\hat{\\boldsymbol{}}_0\\): $$\\mathcal{L}_E(\\theta_C \\mid     \\boldsymbol{y}_E, \\hat{\\boldsymbol{}}_0) \\propto \\exp \\left( \\sum_{=1}^{N_{EC}}     \\hat{}_{0i} \\left[ y_i \\log(\\theta_C) + (1 - y_i) \\log(1 - \\theta_C) \\right] \\right)$$ IPW power prior: $$\\theta_C \\mid \\boldsymbol{y}_E, \\hat{\\boldsymbol{}}_0     \\sim \\mbox{Beta} \\left( \\sum_{=1}^{N_{EC}} \\hat{}_{0i} y_i + \\nu_0,     \\sum_{=1}^{N_{EC}} \\hat{}_{0i} (1 - y_i) + \\phi_0 \\right)$$ Defining weights \\(\\hat{\\boldsymbol{}}_0\\) equal 1 results conventional beta power prior.","code":""},{"path":[]},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_beta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Power Prior Beta — calc_power_prior_beta","text":"","code":"library(distributional) library(dplyr) # This function can be used directly on the data calc_power_prior_beta(external_data = ex_binary_df,                       response = y,                       prior = dist_beta(0.5, 0.5)) #> <distribution[1]> #> [1] Beta(78, 74)  # Or this function can be used with a propensity score object ps_obj <- calc_prop_scr(internal_df = filter(int_binary_df, trt == 0),                         external_df = ex_binary_df,                         id_col = subjid,                         model = ~ cov1 + cov2 + cov3 + cov4)  calc_power_prior_beta(ps_obj,                       response = y,                       prior = dist_beta(0.5, 0.5)) #> <distribution[1]> #> [1] Beta(45, 37)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Power Prior Normal — calc_power_prior_norm","title":"Calculate Power Prior Normal — calc_power_prior_norm","text":"Calculate (potentially inverse probability weighted) normal power prior using external data.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Power Prior Normal — calc_power_prior_norm","text":"","code":"calc_power_prior_norm(   external_data,   response,   prior = NULL,   external_sd = NULL )"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Power Prior Normal — calc_power_prior_norm","text":"external_data can either prop_scr_obj created calling create_prop_scr() tibble external data. just tibble weights assumed 1. external data arm(s) interest included object (e.g., external control data creating power prior control mean) response Name response variable prior Either NULL normal distributional object initial prior parameter interest (e.g., control mean) external data observed external_sd Standard deviation external response data assumed known. can left NULL assumed unknown","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Power Prior Normal — calc_power_prior_norm","text":"Normal power prior object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_norm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Power Prior Normal — calc_power_prior_norm","text":"Weighted participant-level response data external study incorporated inverse probability weighted (IPW) power prior parameter interest \\(\\theta\\) (e.g., control mean borrowing external control arm). borrowing information external dataset size \\(N_{E}\\), IPW likelihood external response data \\(\\boldsymbol{y}_E\\) weights \\(\\hat{\\boldsymbol{}}_0\\) defined $$\\mathcal{L}_E(\\theta \\mid \\boldsymbol{y}_E, \\hat{\\boldsymbol{}}_0,   \\sigma_{E}^2) \\propto \\exp \\left( -\\frac{1}{2 \\sigma_{E}^2}   \\sum_{=1}^{N_{E}} \\hat{}_{0i} (y_i - \\theta)^2 \\right).$$ prior argument either distributional object family type normal NULL, corresponding use normal initial prior improper uniform initial prior (.e., \\(\\pi(\\theta) \\propto   1\\)), respectively. external_sd argument can positive value external standard deviation assumed known left NULL otherwise. external_sd = NULL, prior must NULL indicate use improper uniform initial prior \\(\\theta\\), improper prior defined unknown external standard deviation \\(\\pi(\\sigma_E^2)   \\propto (\\sigma_E^2)^{-1}\\). details IPW power prior case follows: external_sd = positive value (\\(\\sigma_E^2\\) known): either proper normal improper uniform initial prior, IPW weighted power prior \\(\\theta\\) normal distribution. external_sd = NULL (\\(\\sigma_E^2\\) unknown): improper priors \\(\\theta\\) \\(\\sigma_E^2\\), marginal IPW weighted power prior \\(\\theta\\) integrating \\(\\sigma_E^2\\) non-standardized \\(t\\) distribution. Defining weights \\(\\hat{\\boldsymbol{}}_0\\) equal 1 results conventional normal (\\(t\\)) power prior external standard deviation known (unknown).","code":""},{"path":[]},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Power Prior Normal — calc_power_prior_norm","text":"","code":"library(distributional) library(dplyr) # This function can be used directly on the data calc_power_prior_norm(ex_norm_df,                       response = y,                       prior = dist_normal(50, 10),                       external_sd = 0.15) #> <distribution[1]> #> [1] N(0.59, 0.00015)  # Or this function can be used with a propensity score object ps_obj <- calc_prop_scr(internal_df = filter(int_norm_df, trt == 0),                         external_df = ex_norm_df,                         id_col = subjid,                         model = ~ cov1 + cov2 + cov3 + cov4) calc_power_prior_norm(ps_obj,                       response = y,                       prior = dist_normal(50, 10),                       external_sd = 0.15) #> <distribution[1]> #> [1] N(0.69, 0.00037)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_weibull.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Power Prior Weibull — calc_power_prior_weibull","title":"Calculate Power Prior Weibull — calc_power_prior_weibull","text":"Calculate approximate (potentially inverse probability weighted) multivariate normal power prior log-shape log-inverse-scale parameters Weibull likelihood external time--event control data.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_weibull.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Power Prior Weibull — calc_power_prior_weibull","text":"","code":"calc_power_prior_weibull(   external_data,   response,   event,   intercept,   shape,   approximation = c(\"Laplace\", \"MCMC\"),   ... )"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_weibull.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Power Prior Weibull — calc_power_prior_weibull","text":"external_data can either prop_scr_obj created calling create_prop_scr() tibble external data. just tibble weights assumed 1. external data arm(s) interest included object (e.g., external control data creating power prior control Weibull shape intercept parameters) response Name response variable event Name event indicator variable (1: event; 0: censored) intercept Normal distributional object initial prior intercept (.e., log-inverse-scale) parameter shape Integer value scale half-normal prior shape parameter approximation Type approximation used. Either Laplace MCMC. Laplace used default faster MCMC. ... Arguments passed rstan::sampling (e.g. iter, chains).","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_weibull.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Power Prior Weibull — calc_power_prior_weibull","text":"Multivariate Normal Distributional Object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_weibull.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Power Prior Weibull — calc_power_prior_weibull","text":"Weighted participant-level response data control arm external study incorporated approximated inverse probability weighted (IPW) power prior parameter vector \\(\\boldsymbol{\\theta}_C = \\{\\log(\\alpha), \\beta\\}\\), \\(\\beta = -\\log(\\sigma)\\) intercept parameter Weibull proportional hazards regression model \\(\\alpha\\) \\(\\sigma\\) Weibull shape scale parameters, respectively. borrowing information external dataset size \\(N_{E}\\), IPW likelihood external response data \\(\\boldsymbol{y}_E\\) event indicators \\(\\boldsymbol{\\nu}_E\\) weights \\(\\hat{\\boldsymbol{}}_0\\) defined $$\\mathcal{L}_E(\\alpha, \\sigma \\mid \\boldsymbol{y}_E, \\boldsymbol{\\nu}_E,   \\hat{\\boldsymbol{}}_0) \\propto \\prod_{=1}^{N_E} \\left\\{ \\left( \\frac{\\alpha}{\\sigma} \\right)   \\left( \\frac{y_i}{\\sigma} \\right)^{\\alpha - 1} \\exp \\left( -\\left( \\frac{y_i}{\\sigma} \\right)^\\alpha   \\right) \\right\\}^{\\hat{}_{0i} \\nu_i} \\left\\{ \\exp \\left( -\\left( \\frac{y_i}{\\sigma} \\right)^\\alpha   \\right) \\right\\}^{\\hat{}_{0i}(1 - \\nu_i)}.$$ initial priors intercept parameter \\(\\beta\\) shape parameter \\(\\alpha\\) assumed normal half-normal, respectively, can defined using intercept shape arguments. power prior \\(\\boldsymbol{\\theta}_C\\) closed form, thus approximate via bivariate normal distribution; .e., $$\\boldsymbol{\\theta}_C \\mid \\boldsymbol{y}_E, \\boldsymbol{\\nu}_E, \\hat{\\boldsymbol{}}_0   \\; \\dot\\sim \\; \\mbox{MVN} \\left( \\tilde{\\boldsymbol{\\mu}}_0, \\tilde{\\boldsymbol{\\Sigma}}_0 \\right).$$ approximation = Laplace, \\(\\tilde{\\boldsymbol{\\mu}}_0\\) mode vector IPW power prior \\(\\tilde{\\boldsymbol{\\Sigma}}_0\\) negative inverse Hessian log IPW power prior evaluated mode. approximation = MCMC, MCMC samples obtained IPW power prior, \\(\\tilde{\\boldsymbol{\\mu}}_0\\) \\(\\tilde{\\boldsymbol{\\Sigma}}_0\\) estimated mean vector covariance matrix MCMC samples. Note Laplace approximation method faster due use optimization instead MCMC sampling. first element mean vector first row/column covariance matrix correspond log-shape parameter (\\(\\log(\\alpha)\\)), second element corresponds intercept (\\(\\beta\\), log-inverse-scale) parameter.","code":""},{"path":[]},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_power_prior_weibull.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Power Prior Weibull — calc_power_prior_weibull","text":"","code":"library(distributional) library(dplyr) # This function can be used directly on the data calc_power_prior_weibull(ex_tte_df,                          response = y,                          event = event,                          intercept = dist_normal(0, 10),                          shape = 50,                          approximation = \"Laplace\") #> <distribution[1]> #> [1] MVN[2]  # Or this function can be used with a propensity score object ps_obj <- calc_prop_scr(internal_df = filter(int_tte_df, trt == 0),                         external_df = ex_tte_df,                         id_col = subjid,                         model = ~ cov1 + cov2 + cov3 + cov4) calc_power_prior_weibull(ps_obj,                          response = y,                          event = event,                          intercept = dist_normal(0, 10),                          shape = 50,                          approximation = \"Laplace\") #> <distribution[1]> #> [1] MVN[2]"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_prop_scr.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Propensity Score Object — calc_prop_scr","title":"Create a Propensity Score Object — calc_prop_scr","text":"Calculate propensity scores ATT inverse probability weights participants internal external datasets. relevant treatment arms dataset read (e.g., control arm dataset creating hybrid control arm).","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_prop_scr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Propensity Score Object — calc_prop_scr","text":"","code":"calc_prop_scr(internal_df, external_df, id_col, model, ...)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_prop_scr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Propensity Score Object — calc_prop_scr","text":"internal_df Internal dataset one row per subject variables needed run model external_df External dataset one row per subject variables needed run model id_col Name column datasets used identify subject. must across datasets model Model used calculate propensity scores ... Optional arguments","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_prop_scr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Propensity Score Object — calc_prop_scr","text":"prop_scr_obj object, internal external data propensity score inverse probability weight calculated subject.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_prop_scr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Propensity Score Object — calc_prop_scr","text":"subset participants external internal studies want balance covariate distributions (e.g., external control internal control participants constructing hybrid control arm), define study-inclusion propensity score participant $$e(x_i) = P(S_i = 1 \\mid x_i),$$ \\(x_i\\) denotes vector baseline covariates \\(\\)th participant \\(S_i\\) denotes indicator participant enrolled internal trial (\\(S_i = 1\\) internal, \\(S_i = 0\\) external). estimated propensity score \\(\\hat{e}(x_i)\\) obtained using logistic regression. ATT inverse probability weight calculated individual $$\\hat{}_{0i} = \\frac{\\hat{e}(x_i)}{\\hat{P}(S_i = s_i | x_i)} = s_i + (1 - s_i ) \\frac{\\hat{e}(x_i)}{1 - \\hat{e}(x_i)}.$$ weighted estimator, data participants external study given weight \\(\\hat{e}(x_i)⁄(1 - \\hat{e}(x_i))\\) whereas data participants internal trial given weight 1.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/calc_prop_scr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Propensity Score Object — calc_prop_scr","text":"","code":"# This can be used for both continuous and binary data library(dplyr) # Continuous calc_prop_scr(internal_df = filter(int_norm_df, trt == 0),                        external_df = ex_norm_df,                        id_col = subjid,                        model = ~ cov1 + cov2 + cov3 + cov4) #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> • cov1 + cov2 + cov3 + cov4 #>  #> ── Propensity Scores and Weights ─────────────────────────────────────────────── #> • Effective sample size of the external arm: 61 #> # A tibble: 150 × 4 #>    subjid Internal `Propensity Score` `Inverse Probability Weight` #>     <int> <lgl>                 <dbl>                        <dbl> #>  1      1 FALSE                 0.181                        0.221 #>  2      2 FALSE                 0.351                        0.542 #>  3      3 FALSE                 0.456                        0.840 #>  4      4 FALSE                 0.115                        0.130 #>  5      5 FALSE                 0.364                        0.572 #>  6      6 FALSE                 0.377                        0.604 #>  7      7 FALSE                 0.131                        0.150 #>  8      8 FALSE                 0.259                        0.349 #>  9      9 FALSE                 0.235                        0.308 #> 10     10 FALSE                 0.207                        0.261 #> # ℹ 140 more rows #>  #> ── Absolute Standardized Mean Difference ─────────────────────────────────────── #> # A tibble: 4 × 3 #>   covariate diff_unadj diff_adj #>   <chr>          <dbl>    <dbl> #> 1 cov1          0.506   0.104   #> 2 cov2          0.0548  0.104   #> 3 cov3          0.0667  0.00115 #> 4 cov4          0.275   0.00266 # Binary calc_prop_scr(internal_df = filter(int_binary_df, trt == 0),                        external_df = ex_binary_df,                        id_col = subjid,                        model = ~ cov1 + cov2 + cov3 + cov4) #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> • cov1 + cov2 + cov3 + cov4 #>  #> ── Propensity Scores and Weights ─────────────────────────────────────────────── #> • Effective sample size of the external arm: 81 #> # A tibble: 150 × 4 #>    subjid Internal `Propensity Score` `Inverse Probability Weight` #>     <int> <lgl>                 <dbl>                        <dbl> #>  1      1 FALSE                 0.333                        0.500 #>  2      2 FALSE                 0.288                        0.405 #>  3      3 FALSE                 0.539                        1.17  #>  4      4 FALSE                 0.546                        1.20  #>  5      5 FALSE                 0.344                        0.524 #>  6      6 FALSE                 0.393                        0.646 #>  7      7 FALSE                 0.390                        0.639 #>  8      8 FALSE                 0.340                        0.515 #>  9      9 FALSE                 0.227                        0.294 #> 10     10 FALSE                 0.280                        0.389 #> # ℹ 140 more rows #>  #> ── Absolute Standardized Mean Difference ─────────────────────────────────────── #> # A tibble: 4 × 3 #>   covariate diff_unadj diff_adj #>   <chr>          <dbl>    <dbl> #> 1 cov1          0.339  0.0461   #> 2 cov2          0.0450 0.0204   #> 3 cov3          0.160  0.000791 #> 4 cov4          0.308  0.00857"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/ex_binary_df.html","id":null,"dir":"Reference","previous_headings":"","what":"External Binary Control Data for Propensity Score Balancing — ex_binary_df","title":"External Binary Control Data for Propensity Score Balancing — ex_binary_df","text":"simulated dataset used illustrate Bayesian dynamic borrowing case borrowing external control arm binary endpoint, baseline covariate distributions internal external data balanced via inverse probability weighting.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/ex_binary_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"External Binary Control Data for Propensity Score Balancing — ex_binary_df","text":"","code":"ex_binary_df"},{"path":[]},{"path":"https://gsk-biostatistics.github.io/beastt/reference/ex_binary_df.html","id":"ex-binary-df","dir":"Reference","previous_headings":"","what":"ex_binary_df","title":"External Binary Control Data for Propensity Score Balancing — ex_binary_df","text":"data frame 150 rows 6 columns: subjid Unique subject ID cov1 Covariate 1, normally distributed around 65 SD 10 cov2 Covariate 2, binary (0 vs. 1) 30% participants level 1 cov3 Covariate 3, binary (0 vs. 1) 40% participants level 1 cov4 Covariate 4, binary (0 vs. 1) 50% participants level 1 y Response, binary (0 vs. 1)","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/ex_norm_df.html","id":null,"dir":"Reference","previous_headings":"","what":"External Normal Control Data for Propensity Score Balancing — ex_norm_df","title":"External Normal Control Data for Propensity Score Balancing — ex_norm_df","text":"simulated dataset used illustrate Bayesian dynamic borrowing case borrowing external control arm normal endpoint, baseline covariate distributions internal external data balanced via inverse probability weighting.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/ex_norm_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"External Normal Control Data for Propensity Score Balancing — ex_norm_df","text":"","code":"ex_norm_df"},{"path":[]},{"path":"https://gsk-biostatistics.github.io/beastt/reference/ex_norm_df.html","id":"ex-norm-df","dir":"Reference","previous_headings":"","what":"ex_norm_df","title":"External Normal Control Data for Propensity Score Balancing — ex_norm_df","text":"data frame 150 rows 6 columns: subjid Unique subject ID cov1 Covariate 1, normally distributed around 50 SD 10 cov2 Covariate 2, binary (0 vs. 1) 20% participants level 1 cov3 Covariate 3, binary (0 vs. 1) 60% participants level 1 cov4 Covariate 4, binary (0 vs. 1) 30% participants level 1 y Response, normally distributed SD 0.15","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/ex_tte_df.html","id":null,"dir":"Reference","previous_headings":"","what":"External Time-to-Event Control Data for Propensity Score Balancing — ex_tte_df","title":"External Time-to-Event Control Data for Propensity Score Balancing — ex_tte_df","text":"simulated dataset used illustrate Bayesian dynamic borrowing case borrowing external control arm time--event endpoint, baseline covariate distributions internal external data balanced via inverse probability weighting.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/ex_tte_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"External Time-to-Event Control Data for Propensity Score Balancing — ex_tte_df","text":"","code":"ex_tte_df"},{"path":[]},{"path":"https://gsk-biostatistics.github.io/beastt/reference/ex_tte_df.html","id":"ex-tte-df","dir":"Reference","previous_headings":"","what":"ex_tte_df","title":"External Time-to-Event Control Data for Propensity Score Balancing — ex_tte_df","text":"data frame 150 rows 9 columns: subjid Unique subject ID y Response (observed time participant either event censored) enr_time Enrollment time total_time Time study start event Event indicator (1: event; 0: censored) cov1 Covariate 1, normally distributed around 65 SD 10 cov2 Covariate 2, binary (0 vs. 1) 30% participants level 1 cov3 Covariate 3, binary (0 vs. 1) 40% participants level 1 cov4 Covariate 4, binary (0 vs. 1) 50% participants level 1","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/int_binary_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal Binary Data for Propensity Score Balancing — int_binary_df","title":"Internal Binary Data for Propensity Score Balancing — int_binary_df","text":"simulated dataset used illustrate Bayesian dynamic borrowing case borrowing external control arm binary endpoint, baseline covariate distributions internal external data balanced via inverse probability weighting.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/int_binary_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal Binary Data for Propensity Score Balancing — int_binary_df","text":"","code":"int_binary_df"},{"path":[]},{"path":"https://gsk-biostatistics.github.io/beastt/reference/int_binary_df.html","id":"int-binary-df","dir":"Reference","previous_headings":"","what":"int_binary_df","title":"Internal Binary Data for Propensity Score Balancing — int_binary_df","text":"data frame 160 rows 7 columns: subjid Unique subject ID cov1 Covariate 1, normally distributed around 62 sd 8 cov2 Covariate 2, binary (0 vs. 1) 40% participants level 1 cov3 Covariate 3, binary (0 vs. 1) 40% participants level 1 cov4 Covariate 4, binary (0 vs. 1) 60% participants level 1 trt Treatment indicator, 0 = control 1 = active treatment y Response, binary (0 vs. 1)","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/int_norm_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal Normal Data for Propensity Score Balancing — int_norm_df","title":"Internal Normal Data for Propensity Score Balancing — int_norm_df","text":"simulated dataset used illustrate Bayesian dynamic borrowing case borrowing external control arm normal endpoint, baseline covariate distributions internal external data balanced via inverse probability weighting.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/int_norm_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal Normal Data for Propensity Score Balancing — int_norm_df","text":"","code":"int_norm_df"},{"path":[]},{"path":"https://gsk-biostatistics.github.io/beastt/reference/int_norm_df.html","id":"int-norm-df","dir":"Reference","previous_headings":"","what":"int_norm_df","title":"Internal Normal Data for Propensity Score Balancing — int_norm_df","text":"data frame 120 rows 7 columns: subjid Unique subject ID cov1 Covariate 1, normally distributed around 55 SD 8 cov2 Covariate 2, binary (0 vs. 1) 30% participants level 1 cov3 Covariate 3, binary (0 vs. 1) 50% participants level 1 cov4 Covariate 4, binary (0 vs. 1) 30% participants level 1 trt Treatment indicator, 0 = control 1 = active treatment y Response, normally distributed SD 0.15","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/int_tte_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal Time-to-Event Control Data for Propensity Score Balancing — int_tte_df","title":"Internal Time-to-Event Control Data for Propensity Score Balancing — int_tte_df","text":"simulated dataset used illustrate Bayesian dynamic borrowing case borrowing external control arm time--event endpoint, baseline covariate distributions internal external data balanced via inverse probability weighting.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/int_tte_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal Time-to-Event Control Data for Propensity Score Balancing — int_tte_df","text":"","code":"int_tte_df"},{"path":[]},{"path":"https://gsk-biostatistics.github.io/beastt/reference/int_tte_df.html","id":"int-tte-df","dir":"Reference","previous_headings":"","what":"int_tte_df","title":"Internal Time-to-Event Control Data for Propensity Score Balancing — int_tte_df","text":"data frame 160 rows 10 columns: subjid Unique subject ID y Response (observed time participant either event censored) enr_time Enrollment time total_time Time study start event Event indicator (1: event; 0: censored) trt Treatment indicator, 0 = control 1 = active treatment cov1 Covariate 1, normally distributed around 62 SD 8 cov2 Covariate 2, binary (0 vs. 1) 40% participants level 1 cov3 Covariate 3, binary (0 vs. 1) 40% participants level 1 cov4 Covariate 4, binary (0 vs. 1) 60% participants level 1","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/inv_logit.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse Logit Function — inv_logit","title":"Inverse Logit Function — inv_logit","text":"Inverse Logit Function","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/inv_logit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse Logit Function — inv_logit","text":"","code":"inv_logit(x)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/inv_logit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse Logit Function — inv_logit","text":"x Real number(s) take inverse logit ","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/inv_logit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse Logit Function — inv_logit","text":"Vector probabilities 0 1","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/inv_logit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inverse Logit Function — inv_logit","text":"function short hand \\(\\exp(x)/(1 + \\exp(x))\\).","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/inv_logit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse Logit Function — inv_logit","text":"","code":"inv_logit(0.5) #> [1] 0.6224593"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/is_prop_scr.html","id":null,"dir":"Reference","previous_headings":"","what":"Test If Propensity Score Object — is_prop_scr","title":"Test If Propensity Score Object — is_prop_scr","text":"Test Propensity Score Object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/is_prop_scr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test If Propensity Score Object — is_prop_scr","text":"","code":"is_prop_scr(x)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/is_prop_scr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test If Propensity Score Object — is_prop_scr","text":"x Object test","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/is_prop_scr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test If Propensity Score Object — is_prop_scr","text":"Boolean","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/is_prop_scr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test If Propensity Score Object — is_prop_scr","text":"","code":"library(dplyr) x <- calc_prop_scr(internal_df = filter(int_norm_df, trt == 0),                        external_df = ex_norm_df,                        id_col = subjid,                        model = ~ cov1 + cov2 + cov3 + cov4) is_prop_scr(x) #> [1] TRUE"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/mix_means.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Means of Mixture Components — mix_means","title":"Extract Means of Mixture Components — mix_means","text":"Extract Means Mixture Components","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/mix_means.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Means of Mixture Components — mix_means","text":"","code":"mix_means(x)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/mix_means.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Means of Mixture Components — mix_means","text":"x mixture distributional object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/mix_means.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Means of Mixture Components — mix_means","text":"numeric list object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/mix_means.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Means of Mixture Components — mix_means","text":"distributional object mixture two normal distributions read , function return numeric object means normal component. distributional object mixture two multivariate normal distributions, function return list mean vectors multivariate normal component.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/mix_means.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Means of Mixture Components — mix_means","text":"","code":"library(distributional) mix_norm <- dist_mixture(comp1 = dist_normal(1, 10),                          comp2 = dist_normal(1.5, 12),                          weights = c(.5, .5)) mix_means(mix_norm) #> comp1 comp2  #>   1.0   1.5"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/mix_sigmas.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Standard Deviations of Mixture Components — mix_sigmas","title":"Extract Standard Deviations of Mixture Components — mix_sigmas","text":"Extract Standard Deviations Mixture Components","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/mix_sigmas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Standard Deviations of Mixture Components — mix_sigmas","text":"","code":"mix_sigmas(x)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/mix_sigmas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Standard Deviations of Mixture Components — mix_sigmas","text":"x mixture distributional object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/mix_sigmas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Standard Deviations of Mixture Components — mix_sigmas","text":"numeric list object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/mix_sigmas.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Standard Deviations of Mixture Components — mix_sigmas","text":"distributional object mixture two normal distributions read , function return numeric object standard deviations normal component. distributional object mixture two multivariate normal distributions, function return list covariance matrices multivariate normal component.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/mix_sigmas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Standard Deviations of Mixture Components — mix_sigmas","text":"","code":"library(distributional) mix_norm <- dist_mixture(comp1 = dist_normal(1, 10),                          comp2 = dist_normal(1.5, 12),                          weights = c(.5, .5)) mix_sigmas(mix_norm) #> comp1 comp2  #>    10    12"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/plot_dist.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Distribution — plot_dist","title":"Plot Distribution — plot_dist","text":"Plot Distribution","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/plot_dist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Distribution — plot_dist","text":"","code":"plot_dist(...)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/plot_dist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Distribution — plot_dist","text":"... Distributional object(s) plot. passing multiple objects naming change labels plot, else use distributional format","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/plot_dist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Distribution — plot_dist","text":"ggplot object density provided distribution","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/plot_dist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Distribution — plot_dist","text":"","code":"library(distributional) plot_dist(dist_normal(0, 1))  plot_dist(dist_multivariate_normal(mu = list(c(1, 2)), sigma = list(matrix(c(4, 2, 2, 3), ncol=2))))  #Plotting Multiple plot_dist(dist_normal(0, 1), dist_normal(10, 5))  plot_dist('Prior' = dist_normal(0, 1), 'Posterior' = dist_normal(10, 5))"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_cloud.html","id":null,"dir":"Reference","previous_headings":"","what":"Propensity Score Cloud Plot — prop_scr_cloud","title":"Propensity Score Cloud Plot — prop_scr_cloud","text":"Propensity Score Cloud Plot","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_cloud.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Propensity Score Cloud Plot — prop_scr_cloud","text":"","code":"prop_scr_cloud(x, trimmed_prop_scr = NULL)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_cloud.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Propensity Score Cloud Plot — prop_scr_cloud","text":"x prop_scr object trimmed_prop_scr trimmed prop_scr object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_cloud.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Propensity Score Cloud Plot — prop_scr_cloud","text":"ggplot object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_cloud.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Propensity Score Cloud Plot — prop_scr_cloud","text":"","code":"library(dplyr) ps_obj <- calc_prop_scr(internal_df = filter(int_norm_df, trt == 0),                         external_df = ex_norm_df,                         id_col = subjid,                         model = ~ cov1 + cov2 + cov3 + cov4) ps_obj_trimmed <- trim_ps(ps_obj, low = 0.1, high = 0.6) # Plotting the Propensity Scores prop_scr_cloud(ps_obj, trimmed_prop_scr = ps_obj_trimmed)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_dens.html","id":null,"dir":"Reference","previous_headings":"","what":"Density of the Propensity Score Object — prop_scr_dens","title":"Density of the Propensity Score Object — prop_scr_dens","text":"Plot overlapping density curves propensity scores internal external participants, plot external IPWs.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_dens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density of the Propensity Score Object — prop_scr_dens","text":"","code":"prop_scr_dens(   x,   variable = c(\"propensity score\", \"ps\", \"inverse probability weight\", \"ipw\"),   ... )"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_dens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density of the Propensity Score Object — prop_scr_dens","text":"x Propensity score object variable Variable plot. must either propensity score (\"ps\" \"propensity score\") inverse probability weight (\"ipw\" \"inverse probability weight\") ... Optional arguments geom_density","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_dens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density of the Propensity Score Object — prop_scr_dens","text":"ggplot object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_dens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Density of the Propensity Score Object — prop_scr_dens","text":"","code":"library(dplyr) ps_obj <- calc_prop_scr(internal_df = filter(int_norm_df, trt == 0),                        external_df = ex_norm_df,                        id_col = subjid,                        model = ~ cov1 + cov2 + cov3 + cov4) # Plotting the Propensity Scores prop_scr_dens(ps_obj)  # Or plotting the inverse probability weights prop_scr_dens(ps_obj, variable = \"ipw\")"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_hist.html","id":null,"dir":"Reference","previous_headings":"","what":"Histogram of the Propensity Score Object — prop_scr_hist","title":"Histogram of the Propensity Score Object — prop_scr_hist","text":"Plot overlapping histograms propensity scores internal external participants, plot external IPWs.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_hist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Histogram of the Propensity Score Object — prop_scr_hist","text":"","code":"prop_scr_hist(   x,   variable = c(\"propensity score\", \"ps\", \"inverse probability weight\", \"ipw\"),   ... )"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_hist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Histogram of the Propensity Score Object — prop_scr_hist","text":"x Propensity score object variable Variable plot. must either propensity score (\"ps\" \"propensity score\") inverse probability weight (\"ipw\" \"inverse probability weight\") ... Optional arguments geom_histogram","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_hist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Histogram of the Propensity Score Object — prop_scr_hist","text":"ggplot object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_hist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Histogram of the Propensity Score Object — prop_scr_hist","text":"","code":"library(dplyr) ps_obj <- calc_prop_scr(internal_df = filter(int_norm_df, trt == 0),                        external_df = ex_norm_df,                        id_col = subjid,                        model = ~ cov1 + cov2 + cov3 + cov4) # Plotting the Propensity Scores prop_scr_hist(ps_obj)  # Or plotting the inverse probability weights prop_scr_hist(ps_obj, variable = \"ipw\")"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_love.html","id":null,"dir":"Reference","previous_headings":"","what":"Love Plot of the Absolute Standardized Mean Differences — prop_scr_love","title":"Love Plot of the Absolute Standardized Mean Differences — prop_scr_love","text":"Plot unadjusted IPW-adjusted absolute standardized mean differences covariate.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_love.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Love Plot of the Absolute Standardized Mean Differences — prop_scr_love","text":"","code":"prop_scr_love(x, reference_line = NULL, ...)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_love.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Love Plot of the Absolute Standardized Mean Differences — prop_scr_love","text":"x Propensity score object reference_line Numeric value along x-axis vertical reference line placed ... Optional options geom_point","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_love.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Love Plot of the Absolute Standardized Mean Differences — prop_scr_love","text":"ggplot object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/prop_scr_love.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Love Plot of the Absolute Standardized Mean Differences — prop_scr_love","text":"","code":"library(dplyr) ps_obj <- calc_prop_scr(internal_df = filter(int_norm_df, trt == 0),                        external_df = ex_norm_df,                        id_col = subjid,                        model = ~ cov1 + cov2 + cov3 + cov4) # Plotting the Propensity Scores prop_scr_love(ps_obj, reference_line = 0.1)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. generics glance, tidy","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/rescale_ps.html","id":null,"dir":"Reference","previous_headings":"","what":"Rescale a prop_scr object — rescale_ps","title":"Rescale a prop_scr object — rescale_ps","text":"Rescale prop_scr object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/rescale_ps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rescale a prop_scr object — rescale_ps","text":"","code":"rescale_ps(x, n = NULL, scale_factor = NULL)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/rescale_ps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rescale a prop_scr object — rescale_ps","text":"x prop_scr obj n Desired sample size external data effectively contribute analysis internal trial data. used scale external weights scale_factor specified scale_factor Value multiple weights . used scale external weights n specified","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/rescale_ps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rescale a prop_scr object — rescale_ps","text":"prop_scr object rescaled weights","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/rescale_ps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rescale a prop_scr object — rescale_ps","text":"","code":"library(dplyr) ps_obj <- calc_prop_scr(internal_df = filter(int_binary_df, trt == 0),                        external_df = ex_binary_df,                        id_col = subjid,                        model = ~ cov1 + cov2 + cov3 + cov4) # weights in a propensity score object can be rescaled to achieve a desired effective sample size (i.e., sum of weights) rescale_ps(ps_obj, n = 75) #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> • cov1 + cov2 + cov3 + cov4 #>  #> ── Propensity Scores and Weights ─────────────────────────────────────────────── #> • Effective sample size of the external arm: 75 #> # A tibble: 150 × 4 #>    subjid Internal `Propensity Score` `Inverse Probability Weight` #>     <int> <lgl>                 <dbl>                        <dbl> #>  1      1 FALSE                 0.333                        0.465 #>  2      2 FALSE                 0.288                        0.377 #>  3      3 FALSE                 0.539                        1.09  #>  4      4 FALSE                 0.546                        1.12  #>  5      5 FALSE                 0.344                        0.487 #>  6      6 FALSE                 0.393                        0.601 #>  7      7 FALSE                 0.390                        0.594 #>  8      8 FALSE                 0.340                        0.479 #>  9      9 FALSE                 0.227                        0.273 #> 10     10 FALSE                 0.280                        0.362 #> # ℹ 140 more rows #>  #> ── Absolute Standardized Mean Difference ─────────────────────────────────────── #> # A tibble: 4 × 3 #>   covariate diff_unadj diff_adj #>   <chr>          <dbl>    <dbl> #> 1 cov1          0.339  0.0461   #> 2 cov2          0.0450 0.0204   #> 3 cov3          0.160  0.000791 #> 4 cov4          0.308  0.00857   # Or by a predetermined factor rescale_ps(ps_obj, scale_factor = 1.5) #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> • cov1 + cov2 + cov3 + cov4 #>  #> ── Propensity Scores and Weights ─────────────────────────────────────────────── #> • Effective sample size of the external arm: 121 #> # A tibble: 150 × 4 #>    subjid Internal `Propensity Score` `Inverse Probability Weight` #>     <int> <lgl>                 <dbl>                        <dbl> #>  1      1 FALSE                 0.333                        0.751 #>  2      2 FALSE                 0.288                        0.608 #>  3      3 FALSE                 0.539                        1.75  #>  4      4 FALSE                 0.546                        1.81  #>  5      5 FALSE                 0.344                        0.785 #>  6      6 FALSE                 0.393                        0.970 #>  7      7 FALSE                 0.390                        0.958 #>  8      8 FALSE                 0.340                        0.773 #>  9      9 FALSE                 0.227                        0.441 #> 10     10 FALSE                 0.280                        0.584 #> # ℹ 140 more rows #>  #> ── Absolute Standardized Mean Difference ─────────────────────────────────────── #> # A tibble: 4 × 3 #>   covariate diff_unadj diff_adj #>   <chr>          <dbl>    <dbl> #> 1 cov1          0.339  0.0461   #> 2 cov2          0.0450 0.0204   #> 3 cov3          0.160  0.000791 #> 4 cov4          0.308  0.00857"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/robustify_mvnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Robustify Multivariate Normal Distributions — robustify_mvnorm","title":"Robustify Multivariate Normal Distributions — robustify_mvnorm","text":"Adds vague normal component, level vagueness controlled n parameter","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/robustify_mvnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Robustify Multivariate Normal Distributions — robustify_mvnorm","text":"","code":"robustify_mvnorm(prior, n, weights = c(0.5, 0.5))"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/robustify_mvnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Robustify Multivariate Normal Distributions — robustify_mvnorm","text":"prior Multivariate Normal distributional object n Number theoretical participants (events, time--event data) weights Vector weights, first number corresponds informative component second vague","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/robustify_mvnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Robustify Multivariate Normal Distributions — robustify_mvnorm","text":"mixture distribution","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/robustify_mvnorm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Robustify Multivariate Normal Distributions — robustify_mvnorm","text":"cases time--event endpoint, robust mixture prior can created adding vague multivariate normal component multivariate normal prior mean vector \\(\\boldsymbol{\\mu}\\) covariance matrix \\(\\boldsymbol{\\Sigma}\\). vague component calculated mean vector \\(\\boldsymbol{\\mu}\\) covariance matrix equal \\(\\boldsymbol{\\Sigma} \\times n\\), n specified number theoretical events.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/robustify_mvnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Robustify Multivariate Normal Distributions — robustify_mvnorm","text":"","code":"library(distributional) robustify_mvnorm(       dist_multivariate_normal(mu = list(c(1, 0)), sigma = list(c(10, 5))),        n = 15) #> <distribution[1]> #> [1] mixture(0.5*MVN[2], 0.5*MVN[2])"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/robustify_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Robustify Normal Distributions — robustify_norm","title":"Robustify Normal Distributions — robustify_norm","text":"Adds vague normal component, level vagueness controlled n parameter","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/robustify_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Robustify Normal Distributions — robustify_norm","text":"","code":"robustify_norm(prior, n, weights = c(0.5, 0.5))"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/robustify_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Robustify Normal Distributions — robustify_norm","text":"prior Normal Multivariate Normal distributional object n Number theoretical participants (events, time--event data) weights Vector weights, first number corresponds informative component second vague","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/robustify_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Robustify Normal Distributions — robustify_norm","text":"mixture distribution","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/robustify_norm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Robustify Normal Distributions — robustify_norm","text":"cases normal endpoint, robust mixture prior can created adding vague normal component normal prior mean \\(\\theta\\) variance \\(\\sigma^2\\).vague component calculated mean \\(\\theta\\) variance equal \\(\\sigma^2 \\times n\\), n specified number theoretical participants. robustifying normal power prior calculated external control data n defined number external control participants, vague component correspond one external control participant's worth data.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/robustify_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Robustify Normal Distributions — robustify_norm","text":"","code":"library(distributional) robustify_norm(dist_normal(0,1), n = 15) #> <distribution[1]> #> [1] mixture(0.5*N(0, 1), 0.5*N(0, 15))"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/tidy.prop_scr.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy a(n) prop_scr object — tidy.prop_scr","title":"Tidy a(n) prop_scr object — tidy.prop_scr","text":"Tidy (n) prop_scr object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/tidy.prop_scr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy a(n) prop_scr object — tidy.prop_scr","text":"","code":"# S3 method for class 'prop_scr' tidy(x, ...)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/tidy.prop_scr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy a(n) prop_scr object — tidy.prop_scr","text":"x prop_scr obj ... Unused, included generic consistency .","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/tidy.prop_scr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy a(n) prop_scr object — tidy.prop_scr","text":"tidy tibble::tibble() summarizing results propensity score weighting. tibble id column external data, internal column indicate data external, ps column propensity scores weight column inverse probability weights","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/tidy.prop_scr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tidy a(n) prop_scr object — tidy.prop_scr","text":"","code":"library(dplyr) ps_obj <- calc_prop_scr(internal_df = filter(int_binary_df, trt == 0),                        external_df = ex_binary_df,                        id_col = subjid,                        model = ~ cov1 + cov2 + cov3 + cov4) tidy(ps_obj) #> # A tibble: 150 × 4 #>    subjid internal    ps weight #>     <int> <lgl>    <dbl>  <dbl> #>  1      1 FALSE    0.333  0.500 #>  2      2 FALSE    0.288  0.405 #>  3      3 FALSE    0.539  1.17  #>  4      4 FALSE    0.546  1.20  #>  5      5 FALSE    0.344  0.524 #>  6      6 FALSE    0.393  0.646 #>  7      7 FALSE    0.390  0.639 #>  8      8 FALSE    0.340  0.515 #>  9      9 FALSE    0.227  0.294 #> 10     10 FALSE    0.280  0.389 #> # ℹ 140 more rows"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/trim_ps.html","id":null,"dir":"Reference","previous_headings":"","what":"Trim a prop_scr object — trim_ps","title":"Trim a prop_scr object — trim_ps","text":"Trim prop_scr object","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/trim_ps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trim a prop_scr object — trim_ps","text":"","code":"trim_ps(x, low = NULL, high = NULL, quantile = FALSE)"},{"path":"https://gsk-biostatistics.github.io/beastt/reference/trim_ps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trim a prop_scr object — trim_ps","text":"x prop_scr object low Low cut-participants propensity scores less value (quantile quantile = TRUE) removed.  left NULL lower bound used high High cut-participants propensity scores greater value (quantile quantile = TRUE) removed. left NULL upper bound used quantile True/False value determine cut-values based directly propensity scores (false) quantiles (true). default false.","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/trim_ps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trim a prop_scr object — trim_ps","text":"prop_scr object trimmed propensity score distribution","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/trim_ps.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Trim a prop_scr object — trim_ps","text":"function uses R's default method quantile calculation (type 7)","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/reference/trim_ps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trim a prop_scr object — trim_ps","text":"","code":"library(dplyr) ps_obj <- calc_prop_scr(internal_df = filter(int_binary_df, trt == 0),                        external_df = ex_binary_df,                        id_col = subjid,                        model = ~ cov1 + cov2 + cov3 + cov4) trim_ps(ps_obj, low = 0.3, high = 0.7) #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> • cov1 + cov2 + cov3 + cov4 #>  #> ── Propensity Scores and Weights ─────────────────────────────────────────────── #> • Effective sample size of the external arm: 60 #> # A tibble: 84 × 4 #>    subjid Internal `Propensity Score` `Inverse Probability Weight` #>     <int> <lgl>                 <dbl>                        <dbl> #>  1      1 FALSE                 0.333                        0.500 #>  2      3 FALSE                 0.539                        1.17  #>  3      4 FALSE                 0.546                        1.20  #>  4      5 FALSE                 0.344                        0.524 #>  5      6 FALSE                 0.393                        0.646 #>  6      7 FALSE                 0.390                        0.639 #>  7      8 FALSE                 0.340                        0.515 #>  8     12 FALSE                 0.356                        0.553 #>  9     15 FALSE                 0.344                        0.524 #> 10     17 FALSE                 0.440                        0.785 #> # ℹ 74 more rows #>  #> ── Absolute Standardized Mean Difference ─────────────────────────────────────── #> # A tibble: 4 × 3 #>   covariate diff_unadj diff_adj #>   <chr>          <dbl>    <dbl> #> 1 cov1          0.265    0.434  #> 2 cov2          0.0367   0.0163 #> 3 cov3          0.0123   0.0950 #> 4 cov4          0.272    0.372"},{"path":"https://gsk-biostatistics.github.io/beastt/news/index.html","id":"beastt-003","dir":"Changelog","previous_headings":"","what":"beastt 0.0.3","title":"beastt 0.0.3","text":"Add number functions make easier simulate binary time event data Add trim_ps() rescale_ps() function trim re-scale propensity score object Add prop_scr_cloud() function","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/news/index.html","id":"beastt-002","dir":"Changelog","previous_headings":"","what":"beastt 0.0.2","title":"beastt 0.0.2","text":"CRAN release: 2025-02-24 Add time--event capabilities Fixed bug weights power priors Fixed issue R Version high enough use native pipe","code":""},{"path":"https://gsk-biostatistics.github.io/beastt/news/index.html","id":"beastt-001","dir":"Changelog","previous_headings":"","what":"beastt 0.0.1","title":"beastt 0.0.1","text":"CRAN release: 2024-06-20 Initial CRAN submission.","code":""}]
